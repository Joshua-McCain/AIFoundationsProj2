{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function/Class Definitions & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/raw' # Where all the raw stories are\n",
    "TRAIN_FILE = './data/train.jsonl'\n",
    "TEST_FILE = './data/test.jsonl'\n",
    "CORPUS_FILE = 'corpus.txt' # Where all the raw data will be stored\n",
    "\n",
    "TOKENIZER_PREFIX = 'bpe_tokenizer' # Tokenizer name\n",
    "TOKENIZER_PATH = TOKENIZER_PREFIX + \".model\"\n",
    "PAD_TOKEN_ID = 3\n",
    "\n",
    "VOCAB_SIZE = 10000 # Based on project handout, limit of vocab tokens allowed\n",
    "MAX_TRAIN_SEQ_LEN = 128\n",
    "MAX_GEN_SEQ_LEN = 50\n",
    "\n",
    "\n",
    "\n",
    "#MODIFIABLE CONSTANTS FOR MODEL TRAINING START HERE\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = .002\n",
    "# Dictates creativity of the model, < 1 more deterministic, > 1 more creative/stochastic, 1 is no change from base model.\n",
    "TEMPERATURE = 1.1\n",
    "EARLY_EPOCH_STOP = 4\n",
    "\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = .2\n",
    "# Nucleus sampling, 0 picks from most likely token only, >= 1 picks from all tokens. .75-.9 is a good range\n",
    "TOP_P = .8\n",
    "\n",
    "N_HEADS = 8 # For the transformer model only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Proj2Helper import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    " \n",
    "# Load the pre-trained tokenizer from the .model tokenizer file\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.load(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\" \n",
    "    This function takes in all of the batches from the dataset, which will be jagged arrays, and\n",
    "    inserts padding tokens <pad> such that all of the sequences are the same length. Note that the\n",
    "    Cross Entropy Loss criterion should specify to ignore the index 3 so it does not affect the training.\n",
    "\n",
    "    :param batch: The batch of prompts that form a jagged array to be padded.\n",
    "    :return: The input and label batches properly padded.\n",
    "    \"\"\"\n",
    "\n",
    "    input_batch, target_batch = zip(*batch)\n",
    "    input_batch = nn.utils.rnn.pad_sequence(input_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    target_batch = nn.utils.rnn.pad_sequence(target_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    return input_batch, target_batch\n",
    "\n",
    "def train_model(model, device, tokenizer, model_type=\"\"):\n",
    "    \"\"\" \n",
    "    The main training code generalized for all of the models,\n",
    "    including evaluation metrics such as loss graphs, BLEU score, and Perplexity score.\n",
    "\n",
    "    :param model: The instantiated model needing training.\n",
    "    :param device: The device the model should be trained on, preferrably cuda.\n",
    "    :param tokenizer: The loaded tokenizer trained on the dataset being used for model training.\n",
    "    :return: The progression of training and testing losses.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    # Loading tokenizer file and getting most up to date vocab size\n",
    "    vocab_size = tokenizer.get_piece_size()\n",
    "\n",
    "    # Set up datasets from the given jsonl files for training\n",
    "    train_data = TextDataset(TRAIN_FILE, tokenizer, MAX_TRAIN_SEQ_LEN)\n",
    "    test_data = TextDataset(TEST_FILE, tokenizer, MAX_TRAIN_SEQ_LEN)\n",
    "\n",
    "    # Using pytorch DataLoaders for easy batching, shuffling, etc.\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Adding on a decaying learning rate to the optimizer\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.5)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    for epoch in range(EPOCHS):\n",
    "        #Emptying cache and unused data on every epoch since CUDA would run out of memory otherwise\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "\n",
    "        #Want the model in training mode\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for input_ids, target_ids in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            input_ids = input_ids.to(device)\n",
    "            target_ids = target_ids.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Getting the probability distributions for the prompts...\n",
    "            logits, _ = model(input_ids)\n",
    "\n",
    "            \"\"\"\n",
    "            For understanding this dimension change, understand that the logits are of\n",
    "            dimension (B,S,V) (see forward() function of base model for explanantion) and the targets are of\n",
    "            dimension (B,S) (where each entry is the correct token to predict for that position in the sequence).\n",
    "\n",
    "            For Cross Entropy Loss, we must have 1 prediction for each row in both tensors. Therefore, if we can reduce\n",
    "            each tensor such that it reads the last dimension for each row, the function will work. Aka we would have\n",
    "            dimension (B x S, V) (every row is a token's probability distribution) and\n",
    "            dimension (B x S) (every entry is that token's correct value, in chronological order with the logits)\n",
    "\n",
    "            The .view() function allows us to do this my making the last dimension of each tensor account for each entry.\n",
    "            \"\"\"\n",
    "            loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "\n",
    "            # Adjusting weights...\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Don't want the model to train on testing data, so .eval()\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "\n",
    "        # Evaluate testing loss after training on this epoch to see performance on new data\n",
    "        with torch.no_grad():\n",
    "            for input_ids, target_ids in test_loader:\n",
    "                input_ids = input_ids.to(device)\n",
    "                target_ids = target_ids.to(device)\n",
    "\n",
    "                logits, _ = model(input_ids)\n",
    "\n",
    "                loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "                total_test_loss += loss.item()\n",
    "            \n",
    "            avg_test_loss = total_test_loss / len(test_loader)\n",
    "            test_losses.append(avg_test_loss)\n",
    "            scheduler.step(avg_test_loss)\n",
    "\n",
    "            # If our testing data starts getting worse over time, we can stop it early to reduce losses in accuracy based on a preset constant\n",
    "            if(avg_test_loss < best_test_loss):\n",
    "                best_test_loss = avg_test_loss\n",
    "                no_improve_epochs = 0\n",
    "            else:\n",
    "                no_improve_epochs += 1\n",
    "                \n",
    "        if(no_improve_epochs >= EARLY_EPOCH_STOP):\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Test Loss={avg_test_loss:.4f}\")\n",
    "    print(f\"Model Perplexity: {Perplexity(avg_train_loss):.4f} Model BLEU: {BLEU(model, tokenizer, test_loader):.4f}\")\n",
    "    plotLossOverEpochs(EPOCHS, train_losses, test_losses, model_type)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "def plotLossOverEpochs(epochs, train_loss, test_loss, model_type=\"\"):\n",
    "        \"\"\"\n",
    "        Creates a plot showing the losses over time for a model.\n",
    "\n",
    "        :param epochs: The number of epochs the training took place over\n",
    "        :param train_loss: The losses of training over the epochs\n",
    "        :param test_loss: The losses of testing over the epochs\n",
    "        :param name: The name of the trained model being evaluated\n",
    "        \"\"\"\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(model_type + \" Loss per Epoch\")\n",
    "\n",
    "        x_range = range(1, epochs + 1)\n",
    "\n",
    "        plt.plot(x_range, train_loss)\n",
    "        plt.plot(x_range, test_loss)\n",
    "\n",
    "        plt.plot(x_range, train_loss, label=\"Training Loss\", color='blue')\n",
    "        plt.plot(x_range, test_loss, label=\"Testing Loss\", color='orange')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "#Because the loss is already cross entropy, we can just do the natural exponentiation of the loss\n",
    "#Loss here is the average loss across tokens\n",
    "def Perplexity(loss):\n",
    "    return math.exp(loss)\n",
    "\n",
    "def BLEU(model, tokenizer, test_loader):\n",
    "    \"\"\"\n",
    "        Evaluates BLEU score of the entire model by getting probabilities.\n",
    "\n",
    "        :param epochs: The number of epochs the training took place over\n",
    "        :param train_loss: The losses of training over the epochs\n",
    "        :param test_loss: The losses of testing over the epochs\n",
    "        :param name: The name of the trained model being evaluated\n",
    "        :return: The overall BLEU scoring of the prompts and completions ran on\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    references = []\n",
    "    candidates = []\n",
    "    samples_processed = 0\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # We really just want the raw prompts and completions to get rid of unnecessary padding\n",
    "        for input_ids, target_ids in test_loader:\n",
    "\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            # The model does teacher forcing predictions, which is exactly what we need to compare with the labels\n",
    "            logits, _ = model(input_ids)\n",
    "            # Taking the best token from each probability distribution for comparison against the labels\n",
    "            predicted_ids = torch.argmax(logits, dim=-1).cpu().tolist()\n",
    "            target_ids = target_ids.cpu().tolist()\n",
    "\n",
    "            for predicted, target in zip(predicted_ids, target_ids):\n",
    "\n",
    "                # Process 250 samples so it doesnt run forever\n",
    "                if samples_processed > 250:\n",
    "                    break\n",
    "\n",
    "                # For each prediction vector and label vector, decode it and add it to a list for BLEU scoring\n",
    "                pred_decode = tokenizer.decode(predicted, out_type=str)\n",
    "                reference = tokenizer.decode(target, out_type=str)\n",
    "\n",
    "                samples_processed += 1\n",
    "                \n",
    "                candidates.append(pred_decode.split())\n",
    "                references.append([reference.split()])\n",
    "    \n",
    "    # Compute the corpus-level BLEU score. For the purposes of this project, up to 3-gram comparisons were made\n",
    "    bleu_score = corpus_bleu(references, candidates, weights=(.33, .34, .33, 0), smoothing_function=smoothing_function)\n",
    "    return bleu_score\n",
    "\n",
    "def ask_model(model, tokenizer, name):\n",
    "    while(1):\n",
    "        print(\"Prompt \" + name + \" (type q to quit): \")\n",
    "        prompt = input()\n",
    "        if prompt.lower() == \"q\":\n",
    "            break\n",
    "        else:\n",
    "            print(f\"{name} says: \" + model.prompt(tokenizer, \n",
    "                                               prompt, \n",
    "                                               max_seq_length=MAX_GEN_SEQ_LEN, \n",
    "                                               eos_token_id=2, \n",
    "                                               temperature=TEMPERATURE,\n",
    "                                               device=DEVICE\n",
    "                                              ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer & Preliminary Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_spm = input(\"Train new tokenizer (needed if no .model file in project root)? (y/n): \").lower() == \"y\"\n",
    "if run_spm:\n",
    "    merge_text_files(DATA_DIR, CORPUS_FILE)\n",
    "\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=CORPUS_FILE,\n",
    "        model_prefix=TOKENIZER_PREFIX,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        bos_id=1, # Not starting at 0 because that is <unk>.\n",
    "        eos_id=2, # The reason we set the ids this way is because we have manually defined new tokens in the training and\n",
    "        pad_id=PAD_TOKEN_ID, # testing data, so we must specify for the tokenizer training what these tokens are.\n",
    "        user_defined_symbols=\",\".join([\"<bos>\", \"<eos>\", \"<pad>\"])\n",
    "    )\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "tokenizer = load_tokenizer(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 310/310 [01:27<00:00,  3.56it/s]\n",
      "Epoch 2/30: 100%|██████████| 310/310 [01:23<00:00,  3.72it/s]\n",
      "Epoch 3/30: 100%|██████████| 310/310 [01:25<00:00,  3.61it/s]\n",
      "Epoch 4/30: 100%|██████████| 310/310 [01:51<00:00,  2.78it/s]\n",
      "Epoch 5/30: 100%|██████████| 310/310 [01:38<00:00,  3.15it/s]\n",
      "Epoch 6/30: 100%|██████████| 310/310 [01:26<00:00,  3.56it/s]\n",
      "Epoch 7/30: 100%|██████████| 310/310 [01:27<00:00,  3.55it/s]\n",
      "Epoch 8/30: 100%|██████████| 310/310 [01:27<00:00,  3.54it/s]\n",
      "Epoch 9/30: 100%|██████████| 310/310 [01:27<00:00,  3.56it/s]\n",
      "Epoch 10/30: 100%|██████████| 310/310 [01:26<00:00,  3.59it/s]\n",
      "Epoch 11/30: 100%|██████████| 310/310 [01:28<00:00,  3.49it/s]\n",
      "Epoch 12/30: 100%|██████████| 310/310 [01:27<00:00,  3.55it/s]\n",
      "Epoch 13/30: 100%|██████████| 310/310 [01:40<00:00,  3.10it/s]\n",
      "Epoch 14/30: 100%|██████████| 310/310 [01:27<00:00,  3.54it/s]\n",
      "Epoch 15/30: 100%|██████████| 310/310 [01:26<00:00,  3.56it/s]\n",
      "Epoch 16/30: 100%|██████████| 310/310 [01:27<00:00,  3.56it/s]\n",
      "Epoch 17/30: 100%|██████████| 310/310 [01:28<00:00,  3.50it/s]\n",
      "Epoch 18/30: 100%|██████████| 310/310 [01:28<00:00,  3.51it/s]\n",
      "Epoch 19/30: 100%|██████████| 310/310 [01:26<00:00,  3.57it/s]\n",
      "Epoch 20/30: 100%|██████████| 310/310 [01:27<00:00,  3.55it/s]\n",
      "Epoch 21/30: 100%|██████████| 310/310 [01:27<00:00,  3.54it/s]\n",
      "Epoch 22/30: 100%|██████████| 310/310 [01:29<00:00,  3.48it/s]\n",
      "Epoch 23/30: 100%|██████████| 310/310 [01:27<00:00,  3.55it/s]\n",
      "Epoch 24/30: 100%|██████████| 310/310 [01:26<00:00,  3.58it/s]\n",
      "Epoch 25/30: 100%|██████████| 310/310 [01:28<00:00,  3.50it/s]\n",
      "Epoch 26/30: 100%|██████████| 310/310 [01:29<00:00,  3.46it/s]\n",
      "Epoch 27/30: 100%|██████████| 310/310 [01:28<00:00,  3.51it/s]\n",
      "Epoch 28/30: 100%|██████████| 310/310 [01:28<00:00,  3.50it/s]\n",
      "Epoch 29/30: 100%|██████████| 310/310 [01:28<00:00,  3.50it/s]\n",
      "Epoch 30/30: 100%|██████████| 310/310 [01:28<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=4.4582, Test Loss=4.6843\n",
      "[4, 81, 3116, 6, 208, 9, 7, 6, 6, 6, 9, 7, 395, 292, 10, 7, 153, 6, 9, 42, 29, 117, 12, 6, 8, 7, 8, 16, 42, 29, 78, 964, 6, 118, 36, 14, 7, 0, 1876, 6, 175, 466, 103, 349, 6, 7, 6, 10, 295, 6, 10, 10, 48, 7, 7, 91, 7, 153, 11, 8, 11, 8, 44, 7, 7, 7, 693, 11, 204, 138, 747, 6, 6, 7, 88, 12, 7, 0, 1876, 6, 9, 42, 29, 12, 34, 43, 9, 7, 18, 12, 34, 84, 7, 6, 8, 7, 964, 9, 12, 10, 188, 8, 7, 3600, 11, 9, 18, 34, 34, 7, 7, 75, 6, 6, 72, 146, 6, 7, 7, 7, 0, 1876, 6, 7, 7, 7, 6]\n",
      "[4, 0, 1876, 11, 6, 59, 512, 9967, 11, 6, 2738, 7, 5054, 292, 10, 122, 4061, 22, 16, 99, 29, 102, 17, 1272, 33, 46, 8, 16, 27, 29, 13, 128, 273, 466, 36, 134, 28, 0, 1876, 11, 2262, 226, 1008, 349, 12, 487, 84, 7, 499, 138, 525, 5395, 12, 1313, 120, 9, 122, 1021, 11, 2140, 63, 8, 108, 31, 46, 51, 273, 1371, 204, 138, 747, 11, 1922, 76, 894, 134, 28, 0, 1876, 6, 16, 19, 1881, 12, 8918, 22, 9, 6543, 1803, 12, 342, 109, 49, 808, 25, 13, 2356, 3839, 405, 10, 4225, 9, 1716, 3600, 6, 17, 126, 1137, 4085, 17, 7475, 128, 1600, 8, 3052, 345, 1299, 6, 1287, 28, 0, 1876, 1431, 86, 25, 9967, 14]\n",
      "<bos>Iueen, face and the,,, and the deadion of the own, and have not know to,. the. I have not been single,ced in the ⁇ ueequeg, headlinity, the, of name, of of by the the into the owns.s. The the the the friendssstrance,, the more to the ⁇ ueequeg, and have not to bed and the he to be out the,. the single and to of being. thegors and he be be the the man,, He day, the the the ⁇ ueequeg, the the the,\n",
      "<bos> ⁇ ueequegs, or rather Yojos, touching the selection of our craft; I did not like that plan at all. I had not a little relied upon  ⁇ ueequegs sagacity to point out the whaler best fitted to carry us and our fortunes securely. But as all my remonstrances produced no effect upon  ⁇ ueequeg, I was obliged to acquiesce; and accordingly prepared to set about this business with a determined rushing sort of energy and vigor, that should quickly settle that trifling little affair. Next morning early, leaving  ⁇ ueequeg shut up with Yojo in\n",
      "Model Perplexity: 86.3346 Model BLEU: 0.0224\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAabhJREFUeJzt3Xl8FPX9x/HXXrlPQkISSCDcEE65QQUFBbwVL0SFtmpVlFqrVmwreKLWg59txbPeirWoRRERlENFBAQEuYVAOBKOkPvYJLvz+2OSlSUHISTZHO/n47GP2cx8d/ezw7T7dma+36/FMAwDERERkWbC6usCREREROqSwo2IiIg0Kwo3IiIi0qwo3IiIiEizonAjIiIizYrCjYiIiDQrCjciIiLSrCjciIiISLOicCMiIiLNisKNSCPxxhtvYLFYPA+73U5cXBzXXnstO3furNB+1KhRWCwWxo0bV2Hbnj17sFgsPP300551y5Yt87z3999/X+E1U6ZMISQk5KR1zpw5E4vFwtGjR0/xG7Y8U6ZM8fo3PfHha+XH3Nq1a31dikidsvu6ABHx9vrrr9O9e3eKior47rvveOyxx1i6dCnbtm0jMjKyQvtFixbx9ddfc+6559b4M+677z6++eabuixbqhAYGMjXX3/t6zJEWhSFG5FGplevXgwcOBAwz864XC5mzJjBJ598wm9+8xuvtl27dqW0tJT77ruPNWvW1OhswLhx4/jiiy/49NNPufjii+vlO7QkhYWFBAYGVrndarUydOjQBqxIRHRZSqSRKw86hw4dqrDN4XDw2GOP8eOPP/LBBx/U6P2mTJlCz549mT59Oi6Xq05rPd78+fMZNmwYQUFBhIaGct5551W4HHbkyBFuueUWEhIS8Pf3Jzo6mhEjRrBkyRJPm/Xr13PRRRcRExODv78/8fHxXHjhhezfv7/azx81ahS9evXim2++YejQoQQGBtK2bVv+9re/VfjexcXFPProo3Tv3t1Tx29+8xuOHDni1a5Dhw5cdNFFfPTRR/Tv35+AgAAeeuih09xTv14yfOedd7j77ruJjY0lMDCQkSNHsn79+grta7JvAbZt28bEiRNp06YN/v7+JCYmcuONN+J0Or3a5ebmctttt9G6dWuioqK44oorOHjw4Gl/LxFfUbgRaeRSUlIA8yxNZa655hoGDBjAX//6V0pKSk76fjabjVmzZrF582befPPNOq213Hvvvcell15KWFgY77//Pq+99hqZmZmMGjWKb7/91tPuhhtu4JNPPuHBBx/kyy+/5NVXX2XMmDFkZGQAkJ+fz3nnncehQ4f417/+xeLFi5k9ezaJiYnk5uaetI709HSuvfZaJk2axP/+9z+uvPJKHn30Uf7whz942rjdbi699FKeeOIJrrvuOhYsWMATTzzB4sWLGTVqFIWFhV7vuW7dOu69916mTZvGF198wYQJE05aR2lpaYWH2+2u0O6BBx5g9+7dvPrqq7z66qscPHiQUaNGsXv37lPetz/99BODBg1i1apVPPzwwyxcuJBZs2bhdDopLi72+tybbroJh8PBe++9x1NPPcWyZcu4/vrrT/q9RBotQ0Qahddff90AjFWrVhklJSVGbm6u8cUXXxixsbHG2WefbZSUlHi1HzlypJGcnGwYhmEsWbLEAIx//OMfhmEYRkpKigEYf//73z3tly5dagDGhx9+aBiGYZx55plGu3btjMLCQsMwDGPy5MlGcHDwSeucMWOGARhHjhypdLvL5TLi4+ON3r17Gy6Xy7M+NzfXiImJMYYPH+5ZFxISYtx1111VftbatWsNwPjkk09OWteJRo4caQDG//73P6/1N998s2G1Wo29e/cahmEY77//vgEY8+bN82q3Zs0aAzBeeOEFz7r27dsbNpvN2L59e41qmDx5sgFU+hg9erSnXfm/zRlnnGG43W7P+j179hgOh8O46aabDMM4tX177rnnGhEREcbhw4errK/8mLv99tu91j/11FMGYKSlpdXoe4o0NjpzI9LIDB06FIfDQWhoKOPGjSMyMpL//e9/2O1V3yI3evRozj//fB5++OEandEAePLJJ9m/fz//93//V1elA7B9+3YOHjzIDTfcgNX66//FhISEMGHCBFatWkVBQQEAgwcP5o033uDRRx9l1apVFc48de7cmcjISP785z/z4osvsmXLllOqJTQ0lEsuucRr3XXXXYfb7WbFihUAfPbZZ0RERHDxxRd7nVnp168fsbGxLFu2zOv1ffr0qfIsWmUCAwNZs2ZNhccLL7xQoe11113ndd9U+/btGT58OEuXLgVqvm8LCgpYvnw5V199NdHR0Set8cR91KdPHwD27t1b4+8p0pgo3Ig0Mm+99RZr1qzh66+/5ve//z1bt25l4sSJJ33dk08+ydGjR726f1dn+PDhXHbZZTzxxBNkZmaebtke5ZeU4uLiKmyLj4/H7XZ7Pu+DDz5g8uTJvPrqqwwbNoxWrVpx4403kp6eDkB4eDjLly+nX79+PPDAAyQnJxMfH8+MGTNqdAmuTZs2FdbFxsZ61Xno0CGysrLw8/PD4XB4PdLT0yt0ea/se1XHarUycODACo/KAlJ5bSeuK6+1pvs2MzMTl8tFu3btalRjVFSU19/+/v4AFS7JiTQV6i0l0sj06NHDcxPxOeecg8vl4tVXX+W///0vV155ZZWv69evHxMnTuTZZ5/lggsuqNFnzZo1i169evH444/XSe3w6w9lWlpahW0HDx7EarV6urS3bt2a2bNnM3v2bFJTU5k/fz73338/hw8f5osvvgCgd+/ezJ07F8Mw2LhxI2+88QYPP/wwgYGB3H///dXWUtlN2OXBqbzO8ptoyz/vRKGhoV5/1+f4NOW1nbiuvNaa7luLxYLNZjvpTdcizZXO3Ig0ck899RSRkZE8+OCDld6EerxHH32U4uLiGvfg6d69O7/97W/5xz/+QWpqal2US7du3Wjbti3vvfcehmF41ufn5zNv3jxPL58TJSYmcscdd3Deeeexbt26CtstFgt9+/blueeeIyIiotI2J8rNzWX+/Ple69577z2sVitnn302ABdddBEZGRm4XK5Kz7B069btVHdBrb3//vte+2zv3r2sXLmSUaNGATXft+U9rT788EMNtigtks7ciDRykZGRTJ8+nfvuu4/33nuv2l4sSUlJ3Hbbbad0H83MmTN59913Wbp0KcHBwTV+3aefflrhrAbAlVdeyVNPPcWkSZO46KKL+P3vf4/T6eTvf/87WVlZPPHEEwBkZ2dzzjnncN1119G9e3dCQ0NZs2YNX3zxBVdccQVg3g/zwgsvcNlll9GxY0cMw+Cjjz4iKyuL884776Q1RkVFcdttt5GamkrXrl35/PPPeeWVV7jttttITEwE4Nprr+Xdd9/lggsu4A9/+AODBw/G4XCwf/9+li5dyqWXXsrll19e4/1yIrfbzapVqyrd1r9/f88lIIDDhw9z+eWXc/PNN5Odnc2MGTMICAhg+vTpgHmJqyb7FuDZZ5/lzDPPZMiQIdx///107tyZQ4cOMX/+fF566aVK/+1Emg2f3s4sIh7lPVfWrFlTYVthYaGRmJhodOnSxSgtLTUMw7u31PGOHDlihIWFnbS31PEeeOABAzil3lJVPcp98sknxpAhQ4yAgAAjODjYGD16tPHdd995thcVFRm33nqr0adPHyMsLMwIDAw0unXrZsyYMcPIz883DMMwtm3bZkycONHo1KmTERgYaISHhxuDBw823njjjZPWWb5/li1bZgwcONDw9/c34uLijAceeKBCz7OSkhLj6aefNvr27WsEBAQYISEhRvfu3Y3f//73xs6dOz3t2rdvb1x44YUn/exy1fWWAjzvXf5v8/bbbxvTpk0zoqOjDX9/f+Oss84y1q5dW+F9T7Zvy23ZssW46qqrjKioKMPPz89ITEw0pkyZYhQVFRmGUfUxV17P0qVLa/xdRRoTi2Ecd25TRKSZGDVqFEePHuXnn3/2dSkntWzZMs455xw+/PDDau+rEpGa0T03IiIi0qwo3IiIiEizostSIiIi0qzozI2IiIg0Kwo3IiIi0qwo3IiIiEiz0uIG8XO73Rw8eJDQ0NB6HUZdRERE6o5hGOTm5hIfH+81cWxlWly4OXjwIAkJCb4uQ0RERGph3759J50UtsWFm/Ihx/ft20dYWJiPqxEREZGayMnJISEhoUZTh7S4cFN+KSosLEzhRkREpImpyS0luqFYREREmhWFGxEREWlWFG5ERESkWWlx99yIiIhvuN1uiouLfV2GNGJ+fn4n7eZdEwo3IiJS74qLi0lJScHtdvu6FGnErFYrSUlJ+Pn5ndb7KNyIiEi9MgyDtLQ0bDYbCQkJdfJf5tL8lA+ym5aWRmJi4mkNtKtwIyIi9aq0tJSCggLi4+MJCgrydTnSiEVHR3Pw4EFKS0txOBy1fh/FZxERqVculwvgtC81SPNXfoyUHzO1pXAjIiINQvP5ycnU1TGicCMiIiLNisKNiIhIAxk1ahR33XVXjdvv2bMHi8XChg0b6q2m5kjhRkRE5AQWi6Xax5QpU2r1vh999BGPPPJIjdsnJCSQlpZGr169avV5NdXcQpR6S9WhlP3FbNlVwoUjg31dioiInIa0tDTP8w8++IAHH3yQ7du3e9YFBgZ6tS8pKalR755WrVqdUh02m43Y2NhTeo3ozE2d+eLbfDom+HHJWD/cbsPX5YiIyGmIjY31PMLDw7FYLJ6/i4qKiIiI4D//+Q+jRo0iICCAd955h4yMDCZOnEi7du0ICgqid+/evP/++17ve+JlqQ4dOvD444/z29/+ltDQUBITE3n55Zc92088o7Js2TIsFgtfffUVAwcOJCgoiOHDh3sFL4BHH32UmJgYQkNDuemmm7j//vvp169frfeH0+lk2rRpxMTEEBAQwJlnnsmaNWs82zMzM5k0aRLR0dEEBgbSpUsXXn/9dcAcwPGOO+4gLi6OgIAAOnTowKxZs2pdS00o3NSRIX0CAHA7HezaV+LjakREGi/DgPx83zyMOvxvzz//+c9MmzaNrVu3MnbsWIqKihgwYACfffYZP//8M7fccgs33HADP/zwQ7Xv88wzzzBw4EDWr1/P7bffzm233ca2bduqfc1f/vIXnnnmGdauXYvdbue3v/2tZ9u7777LY489xpNPPsmPP/5IYmIic+bMOa3vet999zFv3jzefPNN1q1bR+fOnRk7dizHjh0D4G9/+xtbtmxh4cKFbN26lTlz5tC6dWsAnn/+eebPn89//vMftm/fzjvvvEOHDh1Oq56TMlqY7OxsAzCys7Pr/L0dYYUGGMYbH9f9e4uINFWFhYXGli1bjMLCQsMwDCMvzzDMmNHwj7y8U6//9ddfN8LDwz1/p6SkGIAxe/bsk772ggsuMP70pz95/h45cqTxhz/8wfN3+/btjeuvv97zt9vtNmJiYow5c+Z4fdb69esNwzCMpUuXGoCxZMkSz2sWLFhgAJ79O2TIEGPq1KledYwYMcLo27dvlXWe+DnHy8vLMxwOh/Huu+961hUXFxvx8fHGU089ZRiGYVx88cXGb37zm0rf+8477zTOPfdcw+12V/n55U48Vo53Kr/fOnNTh8LbmBPCbdhc6uNKRESkvg0cONDrb5fLxWOPPUafPn2IiooiJCSEL7/8ktTU1Grfp0+fPp7n5Ze/Dh8+XOPXxMXFAXhes337dgYPHuzV/sS/T8WuXbsoKSlhxIgRnnUOh4PBgwezdetWAG677Tbmzp1Lv379uO+++1i5cqWn7ZQpU9iwYQPdunVj2rRpfPnll7WupaZ0Q3Edim1bytGdsG2H7rkREalKUBDk5fnus+tKcLB355FnnnmG5557jtmzZ9O7d2+Cg4O56667TjoT+ok3IlsslpNOMHr8a8oHvjv+NScOhmecxvW48tdW9p7l68aPH8/evXtZsGABS5YsYfTo0UydOpWnn36aM844g5SUFBYuXMiSJUu4+uqrGTNmDP/9739rXdPJ6MxNHerQ0Tyw9u7RKJwiIlWxWCA42DeP+hwk+ZtvvuHSSy/l+uuvp2/fvnTs2JGdO3fW3wdWoVu3bqxevdpr3dq1a2v9fp07d8bPz49vv/3Ws66kpIS1a9fSo0cPz7ro6GimTJnCO++8w+zZs71ujA4LC+Oaa67hlVde4YMPPmDevHme+3Xqg87c1KFuXa18Bhw+oN0qItLSdO7cmXnz5rFy5UoiIyN59tlnSU9P9woADeHOO+/k5ptvZuDAgQwfPpwPPviAjRs30rFjx5O+9sReVwA9e/bktttu495776VVq1YkJiby1FNPUVBQwO9+9zsAHnzwQQYMGEBycjJOp5PPPvvM872fe+454uLi6NevH1arlQ8//JDY2FgiIiLq9HsfT7/Cdah/snmaMOeQv48rERGRhva3v/2NlJQUxo4dS1BQELfccguXXXYZ2dnZDVrHpEmT2L17N/fccw9FRUVcffXVTJkypcLZnMpce+21FdalpKTwxBNP4Ha7ueGGG8jNzWXgwIEsWrSIyMhIwJzwcvr06ezZs4fAwEDOOuss5s6dC0BISAhPPvkkO3fuxGazMWjQID7//HOs1vq7eGQxTudCXBOUk5NDeHg42dnZhIWF1el7p+wvpmOCOaPp4WOlREcqO4qIFBUVkZKSQlJSEgEBAb4up0U677zziI2N5e233/Z1KdWq7lg5ld9v/frWoaR2ftgCSnAVOfh+QxGXnBPi65JERKSFKSgo4MUXX2Ts2LHYbDbef/99lixZwuLFi31dWoPRDcV1LCSmCIAfN2kgPxERaXgWi4XPP/+cs846iwEDBvDpp58yb948xowZ4+vSGozO3NSx6PgSslNh8zaXr0sREZEWKDAwkCVLlvi6DJ/SmZs6ltjB7A6+e7e6g4uIiPiCwk0d69rZ3KXp+3RSTERExBcUbupY7542ADLT/XxciYiISMukcFPHhvQ1Q01Rpj8FRdUPny0iIiJ1T+GmjvXtGoDF5gLDytqfi3xdjoiISIujcFPH7HYLQa3NULNmY/WTpYmIiEjdU7ipB1FxZqjZpO7gIiJSA2+88Ua9zrXU0ijc1IP4RPNem19+8XEhIiJSKxaLpdrHlClTav3eHTp0YPbs2V7rrrnmGnbs2HF6RddASwlR6q9cDzp3glXA/r3KjiIiTVFaWprn+QcffMCDDz7oNWN2YGBgnX5eYGBgnb9nS6Zf33qQ3MPsDp5xUN3BRUSaotjYWM8jPDwci8XitW7FihUMGDCAgIAAOnbsyEMPPURpaann9TNnziQxMRF/f3/i4+OZNm0aAKNGjWLv3r388Y9/9JwFgopnVGbOnEm/fv14++236dChA+Hh4Vx77bXk5uZ62uTm5jJp0iSCg4OJi4vjueeeY9SoUdx11121/t6pqalceumlhISEEBYWxtVXX82hQ4c823/66SfOOeccQkNDCQsLY8CAAaxduxaAvXv3cvHFFxMZGUlwcDDJycl8/vnnta7ldOjMTT0Y1NsBQH6GP263gdWq0YpFRDwMA1wFvvlsWxBYTu//kxctWsT111/P888/z1lnncWuXbu45ZZbAJgxYwb//e9/ee6555g7dy7Jycmkp6fz008/AfDRRx/Rt29fbrnlFm6++eZqP2fXrl188sknfPbZZ2RmZnL11VfzxBNP8NhjjwFw991389133zF//nzatGnDgw8+yLp16+jXr1+tvpdhGFx22WUEBwezfPlySktLuf3227nmmmtYtmwZAJMmTaJ///7MmTMHm83Ghg0bcDjM37ypU6dSXFzMihUrCA4OZsuWLYSE+GYCaYWbejCkTyBYDIwSO5t/KaJ314CTv0hEpKVwFcB/fPOjx9V5YA8+rbd47LHHuP/++5k8eTIAHTt25JFHHuG+++5jxowZpKamEhsby5gxY3A4HCQmJjJ48GAAWrVqhc1mIzQ0lNjY2Go/x+1288YbbxAaGgrADTfcwFdffcVjjz1Gbm4ub775Ju+99x6jR48G4PXXXyc+Pr7W32vJkiVs3LiRlJQUEhISAHj77bdJTk5mzZo1DBo0iNTUVO699166d+8OQJcuXTyvT01NZcKECfTu3duzX3xFl6XqQUiQFf9wszv4qp/UHVxEpDn58ccfefjhhwkJCfE8br75ZtLS0igoKOCqq66isLCQjh07cvPNN/Pxxx97XbKqqQ4dOniCDUBcXByHDx8GYPfu3ZSUlHhCE0B4eDjdunWr9ffaunUrCQkJnmAD0LNnTyIiIti6dStgni266aabGDNmDE888QS7du3ytJ02bRqPPvooI0aMYMaMGWzcuLHWtZwun5+5OXDgAH/+859ZuHAhhYWFdO3alddee40BAwZU2n7ZsmWcc845FdZv3brVkyQbg4jYYg5lBfLTllM/oEVEmjVbkHkGxVeffZrcbjcPPfQQV1xxRYVtAQEBJCQksH37dhYvXsySJUu4/fbb+fvf/87y5cs9l3Bq4sS2FosFt9vsjWsYhmfd8crX14ZhGBXe78T1M2fO5LrrrmPBggUsXLiQGTNmMHfuXC6//HJuuukmxo4dy4IFC/jyyy+ZNWsWzzzzDHfeeWeta6otn4abzMxMRowYwTnnnMPChQuJiYlh165dNeqmtn37dsLCwjx/R0dH12Olpy4uoZRD22DHDk3BICLixWI57UtDvnTGGWewfft2OnfuXGWbwMBALrnkEi655BKmTp1K9+7d2bRpE2eccQZ+fn64XKc3DlqnTp1wOBysXr3ac6YlJyeHnTt3MnLkyFq9Z8+ePUlNTWXfvn2e99yyZQvZ2dn06NHD065r16507dqVP/7xj0ycOJHXX3+dyy+/HICEhARuvfVWbr31VqZPn84rr7zS8sLNk08+SUJCAq+//rpnXYcOHWr02piYmEbdVz+pI2wAUtUdXESkWXnwwQe56KKLSEhI4KqrrsJqtbJx40Y2bdrEo48+yhtvvIHL5WLIkCEEBQXx9ttvExgYSPv27QHzd27FihVce+21+Pv707p161OuITQ0lMmTJ3PvvffSqlUrYmJimDFjBlartdKzL8dzuVxs2LDBa52fnx9jxoyhT58+TJo0idmzZ3tuKB45ciQDBw6ksLCQe++9lyuvvJKkpCT279/PmjVrmDBhAgB33XUX48ePp2vXrmRmZvL11197haKG5NNf3vnz5zNw4ECuuuoqYmJi6N+/P6+88kqNXtu/f3/i4uIYPXo0S5curbKd0+kkJyfH69EQenQ1d+3hAzU/BSkiIo3f2LFj+eyzz1i8eDGDBg1i6NChPPvss57wEhERwSuvvMKIESPo06cPX331FZ9++ilRUVEAPPzww+zZs4dOnTqd1lWHZ599lmHDhnHRRRcxZswYRowYQY8ePQgIqL4TS15eHv379/d6XHDBBVgsFj755BMiIyM5++yzGTNmDB07duSDDz4AwGazkZGRwY033kjXrl25+uqrGT9+PA899BBghqapU6fSo0cPxo0bR7du3XjhhRdq/f1Oh8U4nQt0p6n8H+Duu+/mqquuYvXq1dx111289NJL3HjjjZW+Zvv27Z7xBZxOJ2+//TYvvvgiy5Yt4+yzz67QfubMmZ4df7zs7Gyvy1p1bd6XuVw5NhRbUDGl+RrvRkRarqKiIlJSUkhKSjrpD6/UXn5+Pm3btuWZZ57hd7/7na/LqZXqjpWcnBzCw8Nr9Pvt03Dj5+fHwIEDWblypWfdtGnTWLNmDd9//32N3+fiiy/GYrEwf/78CtucTidOp9Pzd05ODgkJCfUebtKOlhIfbV71S00vIaGNzuCISMukcFM/1q9fz7Zt2xg8eDDZ2dk8/PDDLFu2jF9++aVWl7oag7oKNz69LBUXF0fPnj291vXo0YPU1NRTep+hQ4eyc+fOSrf5+/sTFhbm9WgIca3t2IPNbuDfry9qkM8UEZGW5emnn6Zv376MGTOG/Px8vvnmmyYbbOqST28oHjFihNdcHQA7duzwXLesqfXr1xMXF1eXpdWJ0JgiMlP8WP9zKVeP83U1IiLSnPTv358ff/zR12U0Sj4NN3/84x8ZPnw4jz/+OFdffTWrV6/m5Zdf5uWXX/a0mT59OgcOHOCtt94CYPbs2XTo0IHk5GSKi4t55513mDdvHvPmzfPV16hSTHwpmSmwdcfpdfkTERGRmvNpuBk0aBAff/wx06dP5+GHHyYpKYnZs2czadIkT5u0tDSvy1TFxcXcc889HDhwgMDAQJKTk1mwYAEXXHCBL75CtdonGWz/DlJ2a24pEREf3uIpTURdHSM+vaHYF07lhqTTNe2RY/zjwVbEdMvm0Lbwev0sEZHGqqSkhF9++YX4+HjCw/X/hVK17OxsDh48SOfOnSuM0Hwqv98+n36hOeuXbO7erEP+Pq5ERMR37HY7QUFBHDlyBIfDgdWqwU2lIrfbzZEjRwgKCsJuP714onBTVw79CF9fCYYTrjsIwJC+ZqgpzvInJ99FWLDNlxWKiPiExWIhLi6OlJQU9u7d6+typBGzWq0kJiaedJTlk1G4qSv2QDD2gAE488A/hB5JflgcpRgldr7fUMTYEU13LhURkdPh5+dHly5dKC4u9nUp0oj5+fnVyZk9hZu6Etkd3JgjBx1dD23Pwmq1EBxdRN7BEH7cVKxwIyItmtVq1SB+0iB04bOuWK1glE2zkLHJs7p1XAkAP2/T7OAiIiINQeGmLllCzGXWrwMTtmtvhppdu3xRkIiISMujcFOX7K3MZd6vSaZzJ3N5cJ9uJhYREWkICjd1KSDWXBYc8Kzq29O8relYmibOFBERaQgKN3UpuGxOrOIjnlWD+pr34RRmBFBa2qLGSxQREfEJhZu6FNbFXLqyPasG9PQHqxvDZWP9NqePChMREWk5FG7qUqvksicFnlUB/lYCI4sAWLVB4UZERKS+KdzUpej+5tLmhqIsz+rIOHPQqk1bS31QlIiISMuicFOXwpLMgfwADv/oWR3XzgXAzl98UJOIiEgLo3BTl6xWMMomyTz260B+Hcu6g+/bo90tIiJS3/RrW9csoebyuIH8enYzd/ORg5rtQkREpL4p3NQ1R5S5zNvjWTWoj9kdPO9IAG63uoOLiIjUJ4WbuhYQZy4Lfx3Ib3h/c6I4t9NByv4SX1QlIiLSYijc1LXgRHNZfNSzKjLMhiPU7A7+/U/qDi4iIlKfFG7qWnhXc+nO9l7dxuwOvv5nnbkRERGpTwo3da1Vr7InRV6r27Qzx7jZtkP33IiIiNQnhZu6FnPcQH4Fhz2rO3QwB8DZk2LxRVUiIiIthsJNXQtNBHdZgDmy3rO6W1dzVx/ar+7gIiIi9Unhpj6UD+SX8etAfv17OQDIOezvi4pERERaDIWb+mANM5fZOzyrhvU1Q01Jrj8ZWS5fVCUiItIiKNzUB89AfimeVUntHFgDzJ5SKzcUVfYqERERqQMKN/UhMN5cFqZ5VlmtFkKjzVDz46ZiX1QlIiLSIijc1IfgDuay5KjX6tbxZnfwLdvdiIiISP1QuKkPEeUD+eV4rU7sYN5rs2tXQxckIiLScijc1IfIsoH8LN731nTpbHYRT9tna+iKREREWgyFm/oQc4a5tBqQu9+zuk8Pc4ybzHQ/X1QlIiLSIijc1Ifg2OMG8lvnWT24rDt4UWYARU7ddyMiIlIfFG7qixFoLo9t9qzq390fi80Fbitrf9bs4CIiIvVB4aa+eAby2+lZZbdbCGxt3oezepPCjYiISH1QuKkvfq3NZf4er9VRseZAfpu2aJRiERGR+qBwU18C2prL4wbyA4hPNEPNL+oOLiIiUi8UbupLaAdzecJAfp07mcv9e7XrRURE6oN+YetLeDdzaeR5rU7ubo5xc/Sgo6ErEhERaREUbupLVB9zaXGC+9du3wP7mKEm/2gAbrfhi8pERESaNYWb+hLT31xaDcjd61k9pE8AYGCU2NmyWz2mRERE6prCTX0JaAWust173EB+YcE2/CLMUPPDBs0OLiIiUtcUbupVxYH8ACLamOFmw+bShi5IRESk2VO4qU+2cHN53EB+AHEJZqjZ/ovuuREREalrCjf1yS/aXBakeq1O6mguU1MsDVyQiIhI86dwU58CywbyK0r3Wt2jq7nbDx+0N3RFIiIizZ7CTX0KSTKXJRleq/v3MkNN7uGAhq5IRESk2VO4qU8R5QP55XqtHt7fDDWl+X4cOFzS0FWJiIg0awo39ckzkF+x10B+bWMc2IPMbuAr1xf5ojIREZFmS+GmPkWXD+QHZP3itSk0xuwOvv5ndQcXERGpSwo39ck/DFzmXFIcXe+1KaateTlq6w73ia8SERGR06BwU+8qH8gvMckc4yZld0PXIyIi0rwp3NQ3W4S5zPG+LNWtsznGTfp+dQcXERGpSwo39c0vxlzm7/Va3S/ZDDVZ6X4NXZGIiEizpnBT34LamUvnIa/VQ/qZocaZHUBOvquhqxIREWm2FG7qW2jZXAulx7xW9+zoj8VRCoaFHzaqO7iIiEhdUbipb5HdzaWR57XaarUQ3NoMNWs3aiA/ERGRuqJwU9+ieptLawm4vMe0iYozQ83mbbosJSIiUlcUbupb635gABbg2FavTe3am2Pc/LKrwasSERFpthRu6psjCNxl3b1PGMivS2dzeTDV1sBFiYiINF8KNw0iyFxkbfNa27unGWoy0h0NXZCIiEizpXDTEOwR5vKEgfwG9/YHoPBoAKWlRgMXJSIi0jwp3DSE8oH8CvZ5rR7Yyx+sbgyXjZ92qDu4iIhIXVC4aQhBCeayKN1rdYC/lYBIM9T88FNxQ1clIiLSLCncNISwTuayNLPCpshYM9T8tLm0wjYRERE5dQo3DSGiR9mT/Aqb4hLMMW52/qJ7bkREROqCz8PNgQMHuP7664mKiiIoKIh+/frx448/Vvua5cuXM2DAAAICAujYsSMvvvhiA1VbS637mktrKZR6X37qWDY7Q+oedQcXERGpCz4NN5mZmYwYMQKHw8HChQvZsmULzzzzDBEREVW+JiUlhQsuuICzzjqL9evX88ADDzBt2jTmzZvXcIWfqqjevw7kl7HJa1PPbuY/wdGD9oavS0REpBny6S/qk08+SUJCAq+//rpnXYcOHap9zYsvvkhiYiKzZ88GoEePHqxdu5ann36aCRMm1GO1p8HuZw7kZyuFoz9BmwGeTQP7mLOD5x4J8FV1IiIizYpPz9zMnz+fgQMHctVVVxETE0P//v155ZVXqn3N999/z/nnn++1buzYsaxdu5aSkooTUDqdTnJycrwevhFsLrK8p2AY3s8MNe4iByn71WNKRETkdPk03OzevZs5c+bQpUsXFi1axK233sq0adN46623qnxNeno6bdq08VrXpk0bSktLOXr0aIX2s2bNIjw83PNISEio8+9RI/ZIc5njPZFUVIQNR6gTgJUbnA1dlYiISLPj03Djdrs544wzePzxx+nfvz+///3vufnmm5kzZ061r7NYLF5/G4ZR6XqA6dOnk52d7Xns27evQpsGERBrLgv2V9gUFmOGmvWbK555EhERkVPj03ATFxdHz549vdb16NGD1NTUKl8TGxtLerr3YHiHDx/GbrcTFRVVob2/vz9hYWFeD58oH8iv+FCFTW3amWPcbN/hbsiKREREmiWfhpsRI0awfft2r3U7duygffv2Vb5m2LBhLF682Gvdl19+ycCBA3E4GvEElKHlA/llVdjUIck885Sy2+c980VERJo8n/6a/vGPf2TVqlU8/vjj/PLLL7z33nu8/PLLTJ061dNm+vTp3HjjjZ6/b731Vvbu3cvdd9/N1q1b+fe//81rr73GPffc44uvUHOR5QP5FVTY1K2reTnt0H51BxcRETldPg03gwYN4uOPP+b999+nV69ePPLII8yePZtJkyZ52qSlpXldpkpKSuLzzz9n2bJl9OvXj0ceeYTnn3++8XYDL9e6v7m0lkKJd8Dp19MMNdmH/Bq6KhERkWbHYpTfjdtC5OTkEB4eTnZ2dsPef+MqhbkOcyC/c76HuKGeTbtSi+nc3gw2x7JdRIZptGIREZHjncrvt27yaCg2O7jL7gnK+MlrU1I7B1Z/s6fUyvVFDV2ZiIhIs6Jw05AsIeYyc5vXaqvVQki0GWp+3KTu4CIiIqdD4aYh2VuZy9zdFTZFx5vdwTdvdzVkRSIiIs2Owk1D8i8bWbmSgfzadzRDzY7tFTaJiIjIKVC4aUjBZeP3FB+usKl/P/OfYu8vjXisHhERkSZA4aYhhXU2l67sCpvGjPAHIGt/EKWlLaoDm4iISJ1SuGlIrZLLnlQcyG/UoEAsNhdGiZ1v1xU2bF0iIiLNiMJNQ2rd11zaXODM8doU4G8lLN4MPV+t1OzgIiIitaVw05AiukL53JhH1lfYnNDJ7Ab+w4+aQFNERKS2FG4aktUKRtkUCxkbK2xO7m3ea7Nji/5ZREREaku/og3NEmous3dU2DRisDnHVPqegIasSEREpFlRuGlojihzWclAfhecHQiA81ggBw5rpGIREZHaULhpaAFlA/kVHqiwqVOiH44wcxqGRd+qx5SIiEhtKNw0tKDygfyOVLo5pr0Zblas0pkbERGR2lC4aWjhXcxlJQP5AXTpYU7DsLHi/cYiIiJSAwo3Dc0zkF/ll53O6GcBYO8OTcMgIiJSGwo3DS36DHNpc0PRsQqbPdMwHNA0DCIiIrWhcNPQQtuD2zw7w+GKA/mdMyQQi82Nu9jOyg26qVhERORUKdw0tJMM5BfgbyU0zpyGYfF3moZBRETkVCnc+IJnIL/tlW5O6FwMwOq1moZBRETkVCnc+IKjtbnM3VPp5uReZdMwbNU/j4iIyKnSr6cvBMaZy6KKA/kBnOmZhsG/oSoSERFpNhRufCG4g7ksPlrp5nFl0zAUZQSRdrS0gYoSERFpHhRufKF8ID93TqWbu7T3wxFqjlT8xYqChqpKRESkWVC48YXygfwsVXf1jtY0DCIiIrWicOML5QP5WQ3IT6+0Sefu5uWojZsaqigREZHmQeHGF0LbHTeQ37pKmww4w/yn2aNpGERERE6Jwo2vGAHmMvPnSjefM6xsGob9moZBRETkVCjc+Io1zFxm7ah08+ihv07DsOqnogYsTEREpGlTuPEVR5S5zN9T6eagACshseXTMCjciIiI1JTCja8ExpvLwoNVNvFMw/CjpmEQERGpKYUbXwlJMpclGVU2KZ+GYfsW/TOJiIjUlH41fSW8q7l051bZZET5NAwpmoZBRESkphRufCWqt7m0VH0/zbizzB5VhRmBHMrQNAwiIiI1oXDjK9H9zaXVgNzUSpt0S/LHEeIELHzxjaZhEBERqQmFG18JigFX2e4/vL7KZtEdzCkalmsaBhERkRpRuPGpsoH8jlU+kB9Ap24uADb+1BD1iIiINH0KN75kDTeXOb9U2WRAf3Oahj07NQ2DiIhITSjc+JJfa3OZt6fKJucM9wMgc18QbremYRARETkZhRtfCmxrLovSqmwyZlgQWMumYdiokYpFRERORuHGl0I6mMtqBvILCrASWjYNw5ffKNyIiIicjMKNL0V0M5dG1QP5AbTrZE7DsGadpmEQERE5GYUbX2pVPpCfE9xVB5fk3ua9Nts2659LRETkZPRr6UsxA8ylFchJqbLZsEE2ANI0DYOIiMhJKdz4UkDErwP5Hal6IL/xIwMBKDwayJFMTcMgIiJSHYUbnzODC8c2V9miR5I/9rJpGBau0DQMIiIi1alVuNm3bx/79+/3/L169WruuusuXn755TorrMWwRZjLnJ3VNotub07DsELTMIiIiFSrVuHmuuuuY+nSpQCkp6dz3nnnsXr1ah544AEefvjhOi2w2fOLNpf5e6ttVj4Nw08b67sgERGRpq1W4ebnn39m8ODBAPznP/+hV69erFy5kvfee4833nijLutr/oLKB/I7VG0zzzQMOzQNg4iISHVqFW5KSkrw9zd77ixZsoRLLrkEgO7du5OWVvVou1KJkE7msrTqgfwARg0zp2E4ti9Q0zCIiIhUo1bhJjk5mRdffJFvvvmGxYsXM27cOAAOHjxIVFRUnRbY7IV3NZdGXrXNPNMwOB2s/lkjFYuIiFSlVuHmySef5KWXXmLUqFFMnDiRvn37AjB//nzP5SqpodZ9zKWluNqB/EKCrISUT8OwwtkQlYmIiDRJ9tq8aNSoURw9epScnBwiIyM962+55RaCgoLqrLgWoXV/MDBjZuY2iOpZZdN2HYvZdhBW/6ixbkRERKpSqzM3hYWFOJ1OT7DZu3cvs2fPZvv27cTExNRpgc2efwi4zRGIOVr1QH4Ayb3NMztbt9jquyoREZEmq1bh5tJLL+Wtt94CICsriyFDhvDMM89w2WWXMWfOnDotsGUoO9uVua3aVsMGmifaNA2DiIhI1WoVbtatW8dZZ50FwH//+1/atGnD3r17eeutt3j++efrtMAWwTOQ3y/VNhtXPg3DEU3DICIiUpVahZuCggJCQ0MB+PLLL7niiiuwWq0MHTqUvXurH4xOKuFfdinvJAP5JXfyxx5sTsOw6NvC+q9LRESkCapVuOncuTOffPIJ+/btY9GiRZx//vkAHD58mLCwsDotsEUIbGcundUP5AfQOtHsBr5iVXF9ViQiItJk1SrcPPjgg9xzzz106NCBwYMHM2zYMMA8i9O/f/86LbBFCOtoLkuPnbRpp+7m5agNG+qxHhERkSasVuHmyiuvJDU1lbVr17Jo0SLP+tGjR/Pcc8/VWXEtRkQPc2nkn7Rp/77mNAwpOzUNg4iISGVqNc4NQGxsLLGxsezfvx+LxULbtm01gF9ttTYHQcRaAq5SsFX9z3LOcD/+CRxLNadhsFotDVOjiIhIE1GrMzdut5uHH36Y8PBw2rdvT2JiIhERETzyyCO4qxllV6oQ1cccyM8CHNtcbdMxwwM90zCs3ayRikVERE5UqzM3f/nLX3jttdd44oknGDFiBIZh8N133zFz5kyKiop47LHH6rrO5s0RAG472ErhyAaI7ltl07BgGyFt8shLC2HRikIG9w5ouDpFRESagFqFmzfffJNXX33VMxs4QN++fWnbti233367wk2tBAE5kLXlpC3bdixmexqsXueq/7JERESamFpdljp27Bjdu3evsL579+4cO3byHj/lZs6cicVi8XrExsZW2X7ZsmUV2lssFrZtq35k3ybBXjZHV86ukzZN7m0AsHWzpmEQERE5Ua3CTd++ffnnP/9ZYf0///lP+vTpc0rvlZycTFpamuexadOmk75m+/btXq/p0qXLKX1moxQQby5zqr/nBmDoQDPUpO3WNAwiIiInqtVlqaeeeooLL7yQJUuWMGzYMCwWCytXrmTfvn18/vnnp1aA3V7t2ZrKxMTEEBERcUqvafQ6TICt34NzB5QUmffhVGHcWQHcBxQcDSQjy0VUhM7giIiIlKvVmZuRI0eyY8cOLr/8crKysjh27BhXXHEFmzdv5vXXXz+l99q5cyfx8fEkJSVx7bXXsnv37pO+pn///sTFxTF69GiWLl1am6/Q+PSaCi4r2Nzw87+qbZrc2R97cDEYFr74tqCBChQREWkaLIZhGHX1Zj/99BNnnHEGLlfNbnRduHAhBQUFdO3alUOHDvHoo4+ybds2Nm/eTFRUVIX227dvZ8WKFQwYMACn08nbb7/Niy++yLJlyzj77LMr/Qyn04nT+WuX6ZycHBISEsjOzm58U0X8JxlKt4CjN1y1sdqmsT2zObQ1nFv+ksFLj1bcVyIiIs1JTk4O4eHhNfr9rvUgfnVh/Pjxnue9e/dm2LBhdOrUiTfffJO77767Qvtu3brRrVs3z9/Dhg1j3759PP3001WGm1mzZvHQQw/VffH1odONsP1+KNoCpcVg96u6abdSDm3VNAwiIiInqtVlqfoSHBxM79692blzZ41fM3To0GrbT58+nezsbM9j3759dVFq/ehzZ9mlKRdsfqnapv37lU3DsMOn+VRERKTRaVThxul0snXrVuLi4mr8mvXr11fb3t/fn7CwMK9Ho+UIAr+u5vOd1d+7dM4wc26pjH1BuN11dmVRRESkyTul/+y/4oorqt2elZV1Sh9+zz33cPHFF5OYmMjhw4d59NFHycnJYfLkyYB51uXAgQO89dZbAMyePZsOHTqQnJxMcXEx77zzDvPmzWPevHmn9LmNWtIk+OVvULix2nmmzhsRZE7DUOTgxy1FDOqlkYpFRETgFMNNeHj4SbffeOONNX6//fv3M3HiRI4ePUp0dDRDhw5l1apVtG/fHoC0tDRSU1M97YuLi7nnnns4cOAAgYGBJCcns2DBAi644IJT+RqNW99psONB89LU1teg1+8rbRYWbCMkJp+89GAWf1uocCMiIlKmTntLNQWncre1z8ztCu6d4D8QJqypsln3M4+x/btWXPy7DOa/qh5TIiLSfJ3K73ejuudGynS41lwWbDAvTVWhR3L5NAyWBihKRESkaVC4aYz63Q1uizlL+La3qmw2bJA5MvFBTcMgIiLioXDTGAVEgL2j+Xz7y1U2G3uWeZ9NwZEgMnM0Q7iIiAgo3DRe7a82l/nrwO2utEnvLv7Yg8qmYfhG0zCIiIiAwk3j1f+esktTJbDjvUqbWK0WohILAVixqqQhqxMREWm0FG4aq4BWYDO7xLN1TpXNOnYzbzhet6FFdXoTERGpksJNY5Z4pbnMW1vlpan+fc3lHk3DICIiAijcNG79/gRuwFYMv/y30iYjh5mTa2bsC9Q0DCIiIijcNG7BsWBNMJ9v/WelTc4fEQQWN65CP9ZvK2rA4kRERBonhZvGLqFsPq+c1ZVemooItREcY95U/OU3zoasTEREpFFSuGns+t9XdmnKCSn/q7RJ205mqPl+rca6ERERUbhp7ELiwdrWfL75H5U26ZFsntHZtln/nCIiIvo1bAraXmYus1dVunnoILOn1IHdfg1UkIiISOOlcNMUnHEfGICtEHZ/VmHz2DPLpmE4HETa0aon2hQREWkJFG6agtBEIM58vvn5Cpv7dvMnMLoADAt/mJndsLWJiIg0Mgo3TUX8xeYy67sKm6xWCzfcYvaY+uStELJydWOxiIi0XAo3TUX/8ktTBbB3cYXNzzwQiV94ESW5/vzxkawGL09ERKSxULhpKiI6ATHm803PVtgcEmRlwpR8AN5/NYgiZ+XTNYiIiDR3CjdNSdxF5jLzm0o3/2NmBPbgYpyZgdz3VFbD1SUiItKIKNw0Jf3+XHZpKh/2L62wOSrCxviJuQC89i9/Sks115SIiLQ8CjdNSauuYLQ2n2+seGkK4F+PhmH1L6HgUDAP/TOr4WoTERFpJBRumprY8eYyY3mlmxPaODh3gtkd/Pln7JopXEREWhyFm6amX3mvqVxIW1lpkxceD8PiKCVnfyhP/1vj3oiISMuicNPUtO4FRivz+Ya/V9qkS3s/hl5ghpq/P6l/YhERaVn0y9cUxYw1l0e/rrLJnCeDsdjcHP0ljJc+yGmgwkRERHxP4aYp6ndv2aWpHEhfXWmTvt0C6Dc6E4CHH9WYNyIi0nIo3DRFMf3BiDCf/1T5pSmA5x8PAoubgz9H8MHnuQ1Tm4iIiI8p3DRV0eeZyyNLqmxy5oBAuo/IAmD6DM0WLiIiLYPCTVPV915zacmCw+urbPbsY/4ApKyNZOGK/AYoTERExLcUbpqq2EHgCgcLVfaaAhh/djAdBpj33vzpr84GKk5ERMR3FG6astbnmsvDi6pt9sTDdgC2fhvBtz8W1ndVIiIiPqVw05T1u8dcWo7B0Z+rbHbNBaHE98oCw8q0BwoapjYREREfUbhpyuKGgyvUvDS1/slqm/7tLxYANnwVyfqtRQ1QnIiIiG8o3DR1USPN5aEvqm1267XhRHXKwXBZueMB3VgsIiLNl8JNU9en/NLUUTi2rdqm991vDub3/YJwdu4tru/KREREfELhpqlrNxJcIWWXpp6qtuk9vw0nrF0uRomd2x/QlAwiItI8Kdw0B63OMpfpC6ptZrVauOOP5mB+X88L58DhkvquTEREpMEp3DQHvf5Y9uQw7P6s2qYPTYsgqE0+bqeDqX/Nrv/aREREGpjCTXPQ/jwwYs1LU99dC86qLznZ7RZ+N9UczG/Be2FkZLkaqEgREZGGoXDTXJz/BbisYMuHBedX2/SJeyPwjyykNN+PPzyU1TD1iYiINBCFm+Yiui90+Yv5vOgHWPd0lU2DAqxMvMkczO/D14PJK3A3RIUiIiINQuGmORn6MDh6m883T4esX6ps+tzfInCEOinODuBPj2c2UIEiIiL1T+Gmubnwa3D5g60UPj8H3JWflYkItXHpDXkAvP1iIMUlRkNWKSIiUm8UbpqboNYw+HUwAPbDspurbPrPh8OxBRZTmBHEA8/q7I2IiDQPCjfNUbeJEHmJ+fzg67B3caXN2kTZGXtNLgAv/Z8fpaU6eyMiIk2fwk1zNXYeuKPAasCKCVBS+WzgLzwahtWvlLy0EB6dk9WwNYqIiNQDhZvmymaHMZ+XdQ/Phc/HVdqsfVsHZ19mDub3+ANBrPlZM4aLiEjTpnDTnMUOho53m8/zvoGf/lVps/f+FU5IXB4lef6MHlvKoYzSBixSRESkbincNHcj/g627uboxRv/CNl7KzSJa21n8Rc27MFOcg+GMPi8XPWeEhGRJkvhpiW48Ctw+YGtBBZW3j18aJ9AXn3HicXmInV9JGMmHvNBoSIiIqdP4aYlCImHAS+Z3cPdKfDNtEqbTb4sjLsfM++/+WZeFL//a0YDFikiIlI3FG5aip5TIGys+XzfC3Dgm0qbPf3nVpx/vRlqXp4Vyb/e1czhIiLStCjctCTj54Mrwuwe/vXFUFJ5z6iFb7aiy7BMcFv5w82BfP1D5d3IRUREGiOFm5bE7gfnfgpuC9iy4YuLK21mtVr44YswIjvk4ir046KLYe+BkgYuVkREpHYUblqatmdC4lTzec4S2PzvSptFhtlYsdiBX3gRhUeCGDKmgIIizR4uIiKNn8JNS3T2P8Dayewevu42yDtYabNenQP4YF4pVr9SDm0LZ8Qlmbjd6iIuIiKNm8JNSzX+K3A5wFYMC86tstllo0N4eHYuYLBhcRTX3aUu4iIi0rgp3LRU4e2h72yze7hrO3z7pyqb/uW2SK6+www1H/yjFY+/qBnERUSk8VK4acn63A4hI83ne56D9NVVNn3//1rRd0wGYOFvfwhl/tK8hqlRRETkFCnctHQXfA6uULN7+OIzYdfHlTazWi2s/DSSNt2zcRfbueoKO5t3ORu4WBERkZNTuGnpHEFwzqe/Ts/w/QT4/oFKmwYFWPlhSRCB0QUUZwVw1nlOMnNcDVywiIhI9RRuBNqNhIs3gzvKPIOTMgs+PQ9cFWcHb9/WwWefgi2ghMyUMIaOz1YPKhERaVQUbsQU0Rmu2Q/+A8y/c5fAB50gP71C03OHBPF/rxaA1c2Ola248DfqQSUiIo2Hwo38yhEAE9ZC7O/MXlSkwked4MC3FZpOnRTOzfebvaa+eCuKe55UwBERkcZB4UYqOvdV6PsyuGxgK4CvR8KG5ys0e/mxKM68wpxk89m/RHDb3xRwRETE93wabmbOnInFYvF6xMbGVvua5cuXM2DAAAICAujYsSMvvvhiA1XbwvS6Gc5bCa4QsLlh8x9g8SRwe0/B8NXcVnQanInhsvLio2Z38axc3WQsIiK+4/MzN8nJyaSlpXkemzZtqrJtSkoKF1xwAWeddRbr16/ngQceYNq0acybN68BK25BYgfDVXt/narhyHswry84fx3jxs9hYdt3EVz026OAwcavomjfs4Dv1hf6rGwREWnZfB5u7HY7sbGxnkd0dHSVbV988UUSExOZPXs2PXr04KabbuK3v/0tTz/9dANW3MIEtIKrd0DEReZ9OCU/w4eJkLHF08Rut/Dpa6155vVsbEHF5OwPZeRwO0+8kuWzskVEpOXyebjZuXMn8fHxJCUlce2117J79+4q237//fecf/75XuvGjh3L2rVrKSkpqfQ1TqeTnJwcr4ecIqsVLvgUujwEbgtYM+HzfrDjA69md0+JYOUqNxHtc3EVOZh+Szjn35BBcYm6iouISMPxabgZMmQIb731FosWLeKVV14hPT2d4cOHk5GRUWn79PR02rRp47WuTZs2lJaWcvTo0UpfM2vWLMLDwz2PhISEOv8eLcbgB+HMBeDyNwf8W30tfHu3d5PeAezdHMQZ48ypGha/E0XSGdnsSi32Tc0iItLi+DTcjB8/ngkTJtC7d2/GjBnDggULAHjzzTerfI3FYvH62zCMSteXmz59OtnZ2Z7Hvn376qj6FqrDeLhkOxhtzKMn9Tn430ivAf/Cgm38uDCKOx8+hsXu4uDPEST3dfH+glzf1S0iIi2Gzy9LHS84OJjevXuzc+fOSrfHxsaSnu49qNzhw4ex2+1ERUVV+hp/f3/CwsK8HnKawtvDNakQONT8O38FzE2AlM+9mj3/t1Z89EUhgVEFOLMCmXRpMDdNz9CIxiIiUq8aVbhxOp1s3bqVuLi4SrcPGzaMxYsXe6378ssvGThwIA6HoyFKlHJ2P7j8e2h7O7gBSzqsvBDea+91L85lo0PYuslB+zPM7uKvPRFFn9GZmpNKRETqjU/DzT333MPy5ctJSUnhhx9+4MorryQnJ4fJkycD5iWlG2+80dP+1ltvZe/evdx9991s3bqVf//737z22mvcc889vvoKMvJfMPS/QDuzuzipsPZaeDcWfn4JgPZxDn75IYLLbskAi8HmZa1o36OQFWsLfFm5iIg0Uz4NN/v372fixIl069aNK664Aj8/P1atWkX79u0BSEtLIzU11dM+KSmJzz//nGXLltGvXz8eeeQRnn/+eSZMmOCrryAAnSfAdftgyCfmmDgGYDkEG2+Fd6Jg3dPYrQYfvxTF82/mYA8uJvdgCOec6eCRf2X6unoREWlmLEb5HbktRE5ODuHh4WRnZ+v+m/qS+hWsmgYlW8rO5gCuUOhyFwx6kPU7ShlzYTHHUsz9f+61R1n4VhR+jspvChcRETmV3+9Gdc+NNBOJo+HqzTD6B3OWcTdgy4Xdj8B74fQ/Op29P/kx+EKzy//Xc1sT0ymP/3sr27d1i4hIs6BwI/UndrA5y/i4TRA43BwA0FYA+2YT8kkEP9z9Z+57bD9Wv1Ky94Vy1+Rw4pOz+c8X6jIuIiK1p3Aj9a91L7j8O7h4F4SOAZcVbE5If40nEzpy6N0pjLtsM1jdpG0J55rxoXQdnqkbjkVEpFZ0z400vPx0WH4rZHwGtl+7hBcXB/L97qF8tm48a3YPYt3efnQf5eL150NI7uTvw4JFRMTXTuX3W+FGfKcoC76ZCukfga2o0ibbDnZj3Z4zcAdGccEVvWnV9woIat2wdYqIiM8p3FRD4aaRyk6BXfMgbSlk/wyuNHP+qhO43RZwB2ENSIDIAZAwDpIuAX/9W4qINGcKN9VQuGlCMrbg3vUxq5dvIPdYFr3a/UxcZHrFdm4L2DtAh+uh/z0KOiIizZDCTTUUbpqmgiI302Ye4+v3sugds5lBHdcwsvsKhnT8AT+/42Ycd1vArxt0/h30mWZOEyEiIk2ewk01FG6atowsF7+5N4sFb4fhdjoAg4tGfsHTE/5O14hvsNh+nZ0clw0C+0KP26HHb8CqzoEiIk2Vwk01FG6ah12pxUy+K5eV8yMwXDYAWrXP5B+3v8+1HV7E6twMNvevL3A5IHQw9PojdLxcQUdEpIlRuKmGwk3zsnpTEXdOz2fNogiMUjPkBEUXMOWWLJ4Z/xoB+96C0l1gPe4wdwVAxFnQ98/maMoiItLoKdxUQ+Gmedqe4uTOv+by1UfhuIscADjCirjshnz+Mb2ENnuegb1zwdj/63xXYM55FXU2dL8VOlygMzoiIo2Uwk01FG6at7SjpUybkc3/3g6mJDcAAFtACedemcO/Hg2lS6t0WPsYHPwEOHxC0HFAUB9IuhqSbwf/EF98BRERqYTCTTUUblqGnHwX987K4u2XAyk8EgSAxe5i0Lgs/vF4MIN7B0DGFlj3OBxeAhzyDjpuC1gTIH489J4GUT198j1ERMSkcFMNhZuWpbjE4KF/ZPGv2Xay94WaK61uepyZxd8f9ufCkcHmuvx02PQvSJ0Hzh1e00JgAO5wiBwG3W/SDckiIj6gcFMNhZuWye02eP6tHJ54Cg5tDfesT+yfyT1/tHLbxDDs9rJTN65S2PEe7HwDsleDLd/7zVwOCOwJHa6BXr+H0iLIT4OCQ1B4GIoOQ1EGODPBeQxKsqEkF0rzwJUP7kJwO4FisEVC/EXQ/88QntRg+0NEpKlRuKmGwo28+1kuDz5cyu41EZRfi/ILL2LY+fncOzXg17M55Q79CJueh8OLwZ0G9XHSxgCIgTbjzKCjy2AiIl4UbqqhcCPlFn+fz58fKuKn5WGeHlYAYe3yGHeZk7/9IZhenQO8X1RwtOzy1X+haBuUDxpoAG4rYAMcYPEDSwDYAsEWDPYQsIeCXzj4RYJ/JDjCIO1ryP4ebIW/foYBGK0g5jzo8yeIHVTPe0JEpPFTuKmGwo2cKCvXxd9fyeHdd2HvhvCykAJY3MQn53DNdW7+cls4URE27xe63ZD1izlLuV/E6d2Hs3cx/PwcHPsGbHne21xhEDUK+twN7UbW/jNERJowhZtqKNxIdXbuLebRf+Ty6UcOMlN+PT6sfqV0H5bDLb+1cdvEMPwclmre5TQd+BY2PgtHl4I164Tu6sEQcSb0mgZJF9RfDSIijYzCTTUUbqSmvv6hgCf+WciKz4NwHgv0rHeEFTHs/DzumRrIxaOCq3mHOnDkJ9jwFBxaBJaME4KOHxAIFnvZZTAHWP3KHgFg8wdbQNkjyLxE5ggGe5B5mSysIySeDyHx9fsdRETqgMJNNRRu5FS53Qavzctlzqsl/LTC+/6c0Pg8Bp5VxOUXOZh8eQhhwbZq3uk0HdsBG56EtM+BdO+gczpcDrBGQVASRPaB2DPN0BMUU0cfUIfcbsg/CMHx6o4v0sIo3FRD4UZOR06+eX/O22+fcH8OYHGUEtctjxEjXdxwZQAXnh2E1VpPl69yU2HH+1CcDSX5UJoPpQXgKoTSQrO7uavI7HLucoJRDO5iMEp+fVDgPZ7P8QzA7Qe21mboadUfYs8yQ09ARP18p+O5SiH9eziwHDJ+hNwd4DwI5JgTorotQBQEd4WY4dDhEogbocAj0owp3FRD4Ubqyq7UYma/nseSJfDLhmBK8/y9tjtCnXTul8+Y8+Dma4Lo3TWginfyoaxdkLoIDn0P2T9DUSoYWd4zqh/PANz+ZuhxRII9zOz55RcFgTEQ2AaC20JIOwhJhJC2YLNX/flFWXBgKaR9C5kbIX8XlBwGS/6pd7l3WcESBSHdzMCTdCm0GarAI9JMKNxUQ+FG6oPbbTB/aT7vfuRk5QobadtCPbOUlwuJzaf3kCIuu8jG764Mrdj7qjHJ2AL7voTDP0D2ZnDuByO76tBTFU8XeTvgX9Y9PhgMJ7gywFpc9eU1N2AEgT0agjtCZF9oMwzihkLa97BvERxbA0V7wJpX+fu4rGBtXRZ4zjTP8LQZrMAj0gQp3FRD4UYaQlaui7c/yeOjz0pZ/70f2ftCOP7X12JzE905lyFnlTLxMj+uGhvy6wjJjZXbDRmbYN9iOLoOnEegOAtKc8pGXi4AowgoAUtpzc+8uC1ghIFfHIR2hagzIO5MiD8L7H41ew9nDuz51Axkx34E596qA4/bAkbZeET4l918HVQ2HtHxYxG1goBo84xUUBsIijNvvg5up3Ak4gMKN9VQuBFf2Lm3mFc+yOOLRbB9XRDFWd6XqGyBxXTok8+5o9389poghvYJrOKdmhBnDuTshbx9kL/PnL+r6DAUHTF7dEUPhLajISq5fsKCMwdS5ptneDLXlQWe/NO/EdtlBcLAvy2EdYfoQdD2XIgZoNAjUo8UbqqhcCO+5nYbLF1dwJv/LWLFUiv7fg7FXex9X0pg6wKSBxdy4TgrN18TQtsYRxXvJqekKAsOrYGCtLJ5wI6Y84AVZ5pnoUpyvOcAM8rmAKMULK7qz0a5LWCEgl88hHaD1gOh7SiIHVr9fUfHc+ZB7h7IPwB5B6DwkPkoOgrFx8ARARE9oXU/832DWp/W7hBpShRuqqFwI41NQZGb9z/L4z//K2HtSgfHUkLAOO5X1OKmVVIeA4eXcM3lDq67MIQAf50h8ImCo3BwuXkD9LENkL8bXIfBWlTNvUMWMILBEQcBbcp6tuWAq8AMUDg55Ut55Vw2IBgcURDQFkI7Q2QPaD0A2gwB/5DT+bYijYrCTTUUbqSx23eohFc/yGPBQjdb1gZSeDTIa7vVv4SE5DzOPsfNVRcFMP7MoMZ/v05z58yDA8sgbQUcWw95v0DpYbAWnPplMAMwLGDYgbI5yqxl9wS58sCVCZYCsJ7k/7oNwG0HSyg4osE/pmzARwueojzPLYC1bPUJ28qX9tDjesMlQFiSORCkzh5JA1G4qYbCjTQ1qzYW8u8PCvh6iZU9m4JxFXrfZGsLLKZt93wGDXVxyVg/rhwbQlCAzuw0CiVFcPAbOLgMMtZB0SFwhIJfq7IblmPMG5aD481HTbrPg3lzd+5eSF8FGRsgewfk7wFnOrizwVJYP7PXV1oLZUHMHyyBYAsBR3jZd2xtBqLAWHNkbKsf2APA6igbOdvf/NvmVzbJrD/Yj18GmK9zFZmDNxakQcHhskuKGeDMAGcmlGSZlxRL8ssCYAG4i8ouK5bgCW/YwFK+tJlhDxtY7YDdXFrsZp0Wu1lnSBIMewqCYxtoh0pVFG6qoXAjTVlxicG8L/N4/5NiVn9n5/AvwRgl3j+EFkcpMZ3z6TeohAvPc3DdRSGNu9u51D23G45tgcNrIeMnyNkOhemAGwwD87QOvy49645bb+C9zlUI7nwwCoFisLrqbpTsxs5lhfBRcPZLENHZ19W0WAo31VC4keakoMjNR4vz+WShkzWrbBzYGoKr6ISbj61uItvn0XtAMeefa+P6S0Jo31Y3KMtpKp8KIyfFfOQfMB9Fh8wbtYszoTTbPJNiFGGe4nHza2Aqe245LlAdd8Ws8s8s78ZvBxxg8QdroNmV3x5iPhzh4Agzz4z5tzIHmTRc5tkfl9MMaa7ishG8i8117mJzXflI3u5icJeay4JNYCv+9fMDB8CIFyB2UD3tWKmKwk01FG6kOSstNVj4bQHzPi9i5bdW9mwOpCTnxJGRDULi8+nax8mwoRYuGu3PmKG6b0caCVcplBaVhZECM3RYHBAcV/Nxj+pSaTGsmg4pL4Et31xnAI7uMGQ2tB/b8DW1UAo31VC4kZbE7TZYub6IuZ8VsmIF/LIxoMINymDepBzTsYCefUsYOcLOhPGBJHfyr+QdRVootxvWPQnbngbrMXOdAVgS4YzHoPv1Pi2vJVC4qYbCjbR0P/9SxHv/K2T5t262b3JwbG9whakiAPwiikjoWkj/gW7GnO3gyrHBundHBGDza/DTDODAr+vcrSH5fuj7Rw3mWE8UbqqhcCPiraDIzcIV+Sz4upi1q2H31gDy04OocPODxU1oXAGdkp0MHWJh1DAH558ZRGSYAo+0ULvnw+p7wLXz1/+5uEKh01QY8kjNB288XkkB5O43R/Y2SiF6gLrbl1G4qYbCjcjJpR0t5b9f5PPVihJ+WmfjwI5ASnIrmdXcYhDUupDYJCfde7oZ2N/K6OH+DO8XqHt4pOVIWwnf3QFF63/tgu/yh7aToFXfslGmj5hd14szoTgbSnPN3mfuwuPmZHNVPn6RywYEgb0VBMRBcBJEdIeovtBmkDnnWQugcFMNhRuR2lm/tYiPFhXyzUo32zbZyUgNpLSg8hs8LY5SItoWktCpmN69YdhAO+POCqRTog9uCBVpKBlb4NvbIPebkw+yeDLusv84qMn7uKxAENgiwD8OQjpAeDdz3KTjJ3711U3ZdUThphoKNyJ1w+022LLbyaIVRaz60cXmny0c2O1HbloghqvyS1WO0CKi2xeR2NFF+/bQpaOVXl3t9OvhR5f2flitOtsjzUDufvjmDsj4EvOuY7+yLuvBZYMchh03kGPZQIdBsWYACWtvzjzvCPh1sMZDq83xijyDNR4yR6qmEGzuU6vNbSmb3qV8BGx/sAaY3eltIeYgk45wcISUDWRoP2Fpq7je6jDXW/3Mnm02u/n6bpPqdLcq3FRD4UakfhU53SxbU8jS7538uM5g53Yrh/YG4DxW/UznFruLwEgn4THFRMe6SEgwSOpgpUdXG327+9G/h3+FkZfdboOMbBcp+0vZc6CE/ekuDh5yc+iQwZEMg8wMC9lZFnKyrBTk2CjKs2O1G/QeXMjVV9i4+ZpQwoJ1z5A0Ybmp5mSwGZsgexvk7YGitLLw48Sc9NXdcCNWl3PZ4IbSOn1LhZtqKNyI+Eba0VK+WFHAN6tL2LkT0vZbOXbYTt5RP0ryatLt3MAR5iSkVQklxRacuXZKCxxVniWqCatfKe375DL+Ajd3TAmhR5K6v0sz5cyB/PSyKSwOQeERc7Z559ETprDIA1e+Odhh+cCLRtmAi4b7uHXHDcTo9ShfFwA3ZNfpV1C4qYbCjUjjk5PvYsNWJz9tLWHbL6Xs2mNwcJ+FI+l2so84KMr0rzbEWGxu7EEl+IeUEBTqIiTcTViEm8hWBq1bW4iJthAXYyG+jY09+118/D+DbauDTwhVBpFJuYw4p5jfXRfAJecE6zKZSCOicFMNhRuRpsftNtiaUsyGrcXs2F1KWIiFhHgbifF2kto6iI60nXIQKS01+OCLPN78oJgflvmRsz/Ua7tfRBG9h+Zz5RU2br02lIhQXb4S8SWFm2oo3IhIZdZvLeJfb+Xz5UIb+zeHeg1saHGUktg7l7Hj3VxzcSBnD1BXd5GGpnBTDYUbETmZjCwXL83N4b8fu/l5VXCF+bmsfqW0al9A5x4lDDzDwvkj/TlvWCAB/hqZVqS+KNxUQ+FGRE6F220wb3Eeb8wt5vvlDrJSgyu9/8didxHRroCk7sWc0R/GnOnH+JFB6o0lUkcUbqqhcCMip6OgyM2S7wv4ckUxa3802LXVwbHUINzFlQy1b3UTGltA+67F9OtvMHSAnY4JdhLibXRs51eha7uIVE3hphoKNyJS10pLDZavLWDRCic/rHGzY7ODI3sDcVUxgnM5q18pjuASAkJKCQpzERruJizCILIVtI6CNtEW4tpYaRtro32cnX49/AkJUiCSlknhphoKNyLSENxug7WbnSxYWsj3a9xs22Tj6AE/igvsuAocVJiYtCasbkLaFNCuUzE9exkMH2Rj3MhAkjtpfB5p/hRuqqFwIyK+VlpqsC+9hJQDpexLK+VAuou0slGVMzIMjh2zkJ1pJS/HHFnZmW+nJN+OUVL5LNP2ECfR7Qvp1M3FgP4Wzh3hx5hhQbrsJc2Kwk01FG5EpCkqPxO0aEUhq9e52PqzjYMp/hQeCaTSs0Bl9/u061xMr94GQwfaOKOnH/16+GvMHmmSFG6qoXAjIs3JkcxSFn1byPLvi9nwE6Rsd5C5PxC301Hla+whTkJaFdOqTSlt4t0kJpqTmPbsYqdfTz+6aRJTaYQUbqqhcCMizZ3bbbBqYxFfflPED2vd7NhqJT3Vj8Jj/lVe2jqexe4iINJJeOsSomNLiU8waBdv3tzcLs5G+7Y2ktraSWrnh59DIUgahsJNNRRuRKSlcrsN9h4sYe1mJ5t3lPLLbjd7UyHtgJVjh23mJKa5/tT8ZmcDW1AJ/sGlBIaVEhLuIjzSTasoaN0a2sRYaBtrJbGtjV5dHPTo6K8wJLWmcFMNhRsRkarlFbjNSUy3FbPtFxcpe9zs22ch65iVvCwbhbl2ivMcuIqqvuxVJasbv7BiQqOKaRXjok2cm4QE6JRkpXsnO327O+jewV9TW0ilFG6qoXAjInL6CorcpBwoYc/+UvYeLGX/QTdph9wcOWJwNMNC1jELOVlW8rNtFOY4zDNCRg1Ci9WNf7iT0KgSotqU0ibOTXy8hfhYCwlxNjok2OiUYKdTogZBbGkUbqqhcCMi0vCKnG4273KycVsJO3a72LXHzb59cDjdSuZhO3kZjlO8JAa2gBL8QksICislNMJFRCs3raMNoqMtxMeZYah9WxutI2xEhFuIDLMRFW7THGBN1Kn8fp/8zjIREZHTFOBvZUDPQAb0DKyyTUGRm593Otm0vZitu0rZs9e8JJZxxEpuppX8HDvOXAelBQ4wLLiKHBQWOSg8AhmnUozVjdXhwubnwu7nxubvxuHvxs/fMB8BBgGBBgEBBt27wwuPRmiOsCZGZ25ERKRJKS4xSNlfzO59peZAiAfcHEx3k34IMo5C5jEzDBXk2HHmOXAVW2vUS6wqIbH5vPyqm4kXhtbht5BTpctS1VC4ERFpedxug+w8N8eyXBzLcZOV6yIrx01Orrk+J9cgN88gL98gPx/yCyAnx2DFp2GU5vuBxc05Vx/jo1ciNQiij+iylIiIyHGsVvOem8gwG51O4XXbU5xcPCmTnd9HsvSD1rRdls+cl1zceKn+47gx011VIiIiVeiW5M+OlZH8dXYm9hAnBYeCmXx5KGdfmUFmjsvX5UkVFG5ERERO4pE/RLJts4XuZx4Dw8I386Jo29nJvz/K8XVpUolGE25mzZqFxWLhrrvuqrLNsmXLsFgsFR7btm1ruEJFRKRF6pTox9ZvWvHwPzNxhDopPBLE7yaEMvyyDDKydBanMWkU4WbNmjW8/PLL9OnTp0btt2/fTlpamufRpUuXeq5QRETE9LepkezcaiV51DHAwvf/iyKhs5MX52b7ujQp4/Nwk5eXx6RJk3jllVeIjIys0WtiYmKIjY31PGw23bkuIiINp31bBz8vbcWsl7NwhBVRmBHEbRPDGXJRBkcyS31dXovn83AzdepULrzwQsaMGVPj1/Tv35+4uDhGjx7N0qVL67E6ERGRqt1/cwS7dtjoM9ocRnD1gigSOpfwj3d0FseXfBpu5s6dy7p165g1a1aN2sfFxfHyyy8zb948PvroI7p168bo0aNZsWJFla9xOp3k5OR4PUREROpKQhsHPy2J4unXsvCLKMJ5LJBpN4QzYHwGX3ybT16B29cltjg+G8Rv3759DBw4kC+//JK+ffsCMGrUKPr168fs2bNr/D4XX3wxFouF+fPnV7p95syZPPTQQxXWaxA/ERGpawcOl3DxjTmsXxT160qLm8BWRUS1KyYxyUWP7nBGHztnDfAnubM/VqtmQa+JJjFC8SeffMLll1/udb+My+XCYrFgtVpxOp01upfmscce45133mHr1q2Vbnc6nTidTs/fOTk5JCQkKNyIiEi9+cfb2cycaSFrfxDu4qrHy7X6lxDapojYhBI6dTFI7mFhSD8HowYHERWh+0mP1yTCTW5uLnv37vVa95vf/Ibu3bvz5z//mV69etXofa688kqOHTvG119/XaP2mn5BREQaitttsGmnkxVrnKzbWMq27bAvxUbGAX+KMgPAqPqsjT24GKvdjc3uxmo3sDkMbGVLu93A7mfgcBjYHeAoe+7nBw4/8Pc3aN3aQodEC12S7PTo6KBXV78mPXVEk5h+ITQ0tEKACQ4OJioqyrN++vTpHDhwgLfeeguA2bNn06FDB5KTkykuLuadd95h3rx5zJs3r8HrFxERORmr1ULfbgH07RZQYVtOvovvfixi5fpiNm128ctOK2l77WSnB+Aq9DPntKpjtqBiAiOKCWtVSlSMm9h4g3ZtoVN7K1072unV1Y8uCX7Y7U37UlmjnlsqLS2N1NRUz9/FxcXcc889HDhwgMDAQJKTk1mwYAEXXHCBD6sUERE5dWHBNsafHcz4s4MrbNuVWsymncUUFhkUFBoUFBkUFhkUFWEunebzIqdBkROKi8FZZJjLYigqspCZYSXzqI28Y3ac2f4YpTZcBX7kFfiRdxAOApsqK8zqxhHixBHowi/AjX+Qm4BAN4FBBkEhBsHBEBpqPsJCISLcQmS4lchwC1GRVqIjbURH2Uju5F/fu7BKmhVcRESkmXO7DfYeLOHnX0rYtquE3XvcpO43SDsIGYetZB21U5DlR2meH3D6Z21sQcV1fuapSVyWEhERkYZhtVpIaudHUjs/Lh5VdbuCIjebf3Hyy94Sjma6ycwyyMp1k5VtkJNjkJtrIS8P8vOgIN9KUYGFogILzkIrJU4bpUU2XE4b9gDfTkehcCMiIiIABAVYGdQrgEG9Kt4jdCrcbt/euOzzEYpFRESkefH12D0KNyIiItKsKNyIiIhIs6JwIyIiIs2Kwo2IiIg0Kwo3IiIi0qwo3IiIiEizonAjIiIizYrCjYiIiDQrCjciIiLSrCjciIiISLOicCMiIiLNisKNiIiINCsKNyIiItKs2H1dQEMzDAOAnJwcH1ciIiIiNVX+u13+O16dFhducnNzAUhISPBxJSIiInKqcnNzCQ8Pr7aNxahJBGpG3G43Bw8eJDQ0FIvF4rUtJyeHhIQE9u3bR1hYmI8qbHq032pH+612tN9OnfZZ7Wi/1U597TfDMMjNzSU+Ph6rtfq7alrcmRur1Uq7du2qbRMWFqYDuRa032pH+612tN9OnfZZ7Wi/1U597LeTnbEppxuKRUREpFlRuBEREZFmReHmOP7+/syYMQN/f39fl9KkaL/VjvZb7Wi/nTrts9rRfqudxrDfWtwNxSIiItK86cyNiIiINCsKNyIiItKsKNyIiIhIs6JwIyIiIs2Kws1xXnjhBZKSkggICGDAgAF88803vi6pUZs5cyYWi8XrERsb6+uyGp0VK1Zw8cUXEx8fj8Vi4ZNPPvHabhgGM2fOJD4+nsDAQEaNGsXmzZt9U2wjcbJ9NmXKlArH3tChQ31TbCMxa9YsBg0aRGhoKDExMVx22WVs377dq42OtYpqst90vFU0Z84c+vTp4xmob9iwYSxcuNCz3dfHmsJNmQ8++IC77rqLv/zlL6xfv56zzjqL8ePHk5qa6uvSGrXk5GTS0tI8j02bNvm6pEYnPz+fvn378s9//rPS7U899RTPPvss//znP1mzZg2xsbGcd955nnnQWqKT7TOAcePGeR17n3/+eQNW2PgsX76cqVOnsmrVKhYvXkxpaSnnn38++fn5njY61iqqyX4DHW8nateuHU888QRr165l7dq1nHvuuVx66aWeAOPzY80QwzAMY/Dgwcatt97qta579+7G/fff76OKGr8ZM2YYffv29XUZTQpgfPzxx56/3W63ERsbazzxxBOedUVFRUZ4eLjx4osv+qDCxufEfWYYhjF58mTj0ksv9Uk9TcXhw4cNwFi+fLlhGDrWaurE/WYYOt5qKjIy0nj11VcbxbGmMzdAcXExP/74I+eff77X+vPPP5+VK1f6qKqmYefOncTHx5OUlMS1117L7t27fV1Sk5KSkkJ6errXsefv78/IkSN17J3EsmXLiImJoWvXrtx8880cPnzY1yU1KtnZ2QC0atUK0LFWUyfut3I63qrmcrmYO3cu+fn5DBs2rFEcawo3wNGjR3G5XLRp08ZrfZs2bUhPT/dRVY3fkCFDeOutt1i0aBGvvPIK6enpDB8+nIyMDF+X1mSUH1869k7N+PHjeffdd/n666955plnWLNmDeeeey5Op9PXpTUKhmFw9913c+aZZ9KrVy9Ax1pNVLbfQMdbVTZt2kRISAj+/v7ceuutfPzxx/Ts2bNRHGstblbw6lgsFq+/DcOosE5+NX78eM/z3r17M2zYMDp16sSbb77J3Xff7cPKmh4de6fmmmuu8Tzv1asXAwcOpH379ixYsIArrrjCh5U1DnfccQcbN27k22+/rbBNx1rVqtpvOt4q161bNzZs2EBWVhbz5s1j8uTJLF++3LPdl8eaztwArVu3xmazVUiUhw8frpA8pWrBwcH07t2bnTt3+rqUJqO8d5mOvdMTFxdH+/btdewBd955J/Pnz2fp0qW0a9fOs17HWvWq2m+V0fFm8vPzo3PnzgwcOJBZs2bRt29f/u///q9RHGsKN5j/QAMGDGDx4sVe6xcvXszw4cN9VFXT43Q62bp1K3Fxcb4upclISkoiNjbW69grLi5m+fLlOvZOQUZGBvv27WvRx55hGNxxxx189NFHfP311yQlJXlt17FWuZPtt8roeKucYRg4nc7Gcaw1yG3LTcDcuXMNh8NhvPbaa8aWLVuMu+66ywgODjb27Nnj69IarT/96U/GsmXLjN27dxurVq0yLrroIiM0NFT77AS5ubnG+vXrjfXr1xuA8eyzzxrr16839u7daxiGYTzxxBNGeHi48dFHHxmbNm0yJk6caMTFxRk5OTk+rtx3qttnubm5xp/+9Cdj5cqVRkpKirF06VJj2LBhRtu2bVv0PrvtttuM8PBwY9myZUZaWprnUVBQ4GmjY62ik+03HW+Vmz59urFixQojJSXF2Lhxo/HAAw8YVqvV+PLLLw3D8P2xpnBznH/9619G+/btDT8/P+OMM87w6gooFV1zzTVGXFyc4XA4jPj4eOOKK64wNm/e7OuyGp2lS5caQIXH5MmTDcMwu+jOmDHDiI2NNfz9/Y2zzz7b2LRpk2+L9rHq9llBQYFx/vnnG9HR0YbD4TASExONyZMnG6mpqb4u26cq21+A8frrr3va6Fir6GT7Tcdb5X772996fi+jo6ON0aNHe4KNYfj+WLMYhmE0zDkiERERkfqne25ERESkWVG4ERERkWZF4UZERESaFYUbERERaVYUbkRERKRZUbgRERGRZkXhRkRERJoVhRsRaZEsFguffPKJr8sQkXqgcCMiDW7KlClYLJYKj3Hjxvm6NBFpBuy+LkBEWqZx48bx+uuve63z9/f3UTUi0pzozI2I+IS/vz+xsbFej8jISMC8ZDRnzhzGjx9PYGAgSUlJfPjhh16v37RpE+eeey6BgYFERUVxyy23kJeX59Xm3//+N8nJyfj7+xMXF8cdd9zhtf3o0aNcfvnlBAUF0aVLF+bPn+/ZlpmZyaRJk4iOjiYwMJAuXbpUCGMi0jgp3IhIo/S3v/2NCRMm8NNPP3H99dczceJEtm7dCkBBQQHjxo0jMjKSNWvW8OGHH7JkyRKv8DJnzhymTp3KLbfcwqZNm5g/fz6dO3f2+oyHHnqIq6++mo0bN3LBBRcwadIkjh075vn8LVu2sHDhQrZu3cqcOXNo3bp1w+0AEam9BpuiU0SkzOTJkw2bzWYEBwd7PR5++GHDMMyZmm+99Vav1wwZMsS47bbbDMMwjJdfftmIjIw08vLyPNsXLFhgWK1WIz093TAMw4iPjzf+8pe/VFkDYPz1r3/1/J2Xl2dYLBZj4cKFhmEYxsUXX2z85je/qZsvLCINSvfciIhPnHPOOcyZM8drXatWrTzPhw0b5rVt2LBhbNiwAYCtW7fSt29fgoODPdtHjBiB2+1m+/btWCwWDh48yOjRo6utoU+fPp7nwcHBhIaGcvjwYQBuu+02JkyYwLp16zj//PO57LLLGD58eK2+q4g0LIUbEfGJ4ODgCpeJTsZisQBgGIbneWVtAgMDa/R+DoejwmvdbjcA48ePZ+/evSxYsIAlS5YwevRopk6dytNPP31KNYtIw9M9NyLSKK1atarC3927dwegZ8+ebNiwgfz8fM/27777DqvVSteuXQkNDaVDhw589dVXp1VDdHQ0U6ZM4Z133mH27Nm8/PLLp/V+ItIwdOZGRHzC6XSSnp7utc5ut3tu2v3www8ZOHAgZ555Ju+++y6rV6/mtddeA2DSpEnMmDGDyZMnM3PmTI4cOcKdd97JDTfcQJs2bQCYOXMmt956KzExMYwfP57c3Fy+++477rzzzhrV9+CDDzJgwACSk5NxOp189tln9OjRow73gIjUF4UbEfGJL774gri4OK913bp1Y9u2bYDZk2nu3LncfvvtxMbG8u6779KzZ08AgoKCWLRoEX/4wx8YNGgQQUFBTJgwgWeffdbzXpMnT6aoqIjnnnuOe+65h9atW3PllVfWuD4/Pz+mT5/Onj17CAwM5KyzzmLu3Ll18M1FpL5ZDMMwfF2EiMjxLBYLH3/8MZdddpmvSxGRJkj33IiIiEizonAjIiIizYruuRGRRkdXy0XkdOjMjYiIiDQrCjciIiLSrCjciIiISLOicCMiIiLNisKNiIiINCsKNyIiItKsKNyIiIhIs6JwIyIiIs2Kwo2IiIg0K/8P6RXnlDQ5fQwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([6.685283108680479,\n",
       "  5.933915962711457,\n",
       "  5.3658538510722495,\n",
       "  5.150806153205133,\n",
       "  5.028496219265845,\n",
       "  4.948514289240683,\n",
       "  4.893175781926801,\n",
       "  4.844830223821824,\n",
       "  4.8073778983085385,\n",
       "  4.779558158689929,\n",
       "  4.751704202159758,\n",
       "  4.726996587937878,\n",
       "  4.7050195109459665,\n",
       "  4.686739204775902,\n",
       "  4.674489352010911,\n",
       "  4.682245514469762,\n",
       "  4.65146394852669,\n",
       "  4.631436394106958,\n",
       "  4.623844195950416,\n",
       "  4.605020652278777,\n",
       "  4.592913427660542,\n",
       "  4.584741250930294,\n",
       "  4.573201597890546,\n",
       "  4.564582178669591,\n",
       "  4.560539700908046,\n",
       "  4.492362756113852,\n",
       "  4.476738036063409,\n",
       "  4.4741009189236545,\n",
       "  4.46334506926998,\n",
       "  4.458230450845534],\n",
       " [6.437279719572801,\n",
       "  5.521771186437363,\n",
       "  5.208181320092617,\n",
       "  5.063085256478725,\n",
       "  4.978988849199736,\n",
       "  4.929430069067539,\n",
       "  4.908332635194827,\n",
       "  4.872541189193726,\n",
       "  4.841768784400744,\n",
       "  4.847409456204145,\n",
       "  4.81403861901699,\n",
       "  4.810616591037848,\n",
       "  4.793205285683657,\n",
       "  4.7863067480234,\n",
       "  4.802675925768339,\n",
       "  4.781932023855356,\n",
       "  4.775864387169863,\n",
       "  4.7589550996438055,\n",
       "  4.765594910352658,\n",
       "  4.752437340907561,\n",
       "  4.752096017201741,\n",
       "  4.74427308791723,\n",
       "  4.742437173158694,\n",
       "  4.748047046172313,\n",
       "  4.745815417705438,\n",
       "  4.697316811634944,\n",
       "  4.703889883481539,\n",
       "  4.691181066708687,\n",
       "  4.685518368696555,\n",
       "  4.684266481644068])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Proj2Models import RNNLanguageModel\n",
    "\n",
    "rnn_model = RNNLanguageModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pad_token_id=PAD_TOKEN_ID,\n",
    "    top_p=TOP_P,\n",
    "    name=\"RNN\"\n",
    ").to(device)\n",
    "\n",
    "train_model(rnn_model, device, tokenizer, rnn_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt RNN (type q to quit): \n",
      "LSTM says: There comes home, passed back against the water, as Mr. She smiling. Sheur for writing. Ass I had the childdy persons with them, down into the fact, to breakfast and of men under the towns to in their\n",
      "Prompt RNN (type q to quit): \n",
      "LSTM says: light of uncovered, entirely have seen; it is not existing care for his hand a house, where people, and then raised the world to retreat behind a soul can settle a supplement of our son! I cannot do you? Nicholas left\n",
      "Prompt RNN (type q to quit): \n"
     ]
    }
   ],
   "source": [
    "ask_model(rnn_model, tokenizer, rnn_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/310 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mProj2Models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTMLanguageModel\n\u001b[0;32m      3\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m LSTMLanguageModel(\n\u001b[0;32m      4\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39mVOCAB_SIZE,\n\u001b[0;32m      5\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39mEMBED_DIM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 14\u001b[0m train_model(lstm_model, device, tokenizer, lstm_model\u001b[38;5;241m.\u001b[39mname)\n",
      "Cell \u001b[1;32mIn[9], line 81\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, device, tokenizer, model_type)\u001b[0m\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Getting the probability distributions for the prompts...\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m model(input_ids)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03mFor understanding this dimension change, understand that the logits are of\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03mdimension (B,S,V) (see forward() function of base model for explanantion) and the targets are of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03mThe .view() function allows us to do this my making the last dimension of each tensor account for each entry.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size), target_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\joshm\\miniconda3\\envs\\AI_Foundation_Proj2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshm\\miniconda3\\envs\\AI_Foundation_Proj2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\joshm\\OneDrive\\Desktop\\AI Foundations\\Proj2\\Proj2Models.py:184\u001b[0m, in \u001b[0;36mLSTMLanguageModel.forward\u001b[1;34m(self, input_ids, hidden)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03mThe LSTM implementation of layer propagation. See the BaseLanguageModel for in depth hyperparameter and output explanation.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03mThe fully connected layer at the end gives us our probability distributions.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    183\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_ids)\n\u001b[1;32m--> 184\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embeds, hidden)\n\u001b[0;32m    185\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, hidden\n",
      "File \u001b[1;32mc:\\Users\\joshm\\miniconda3\\envs\\AI_Foundation_Proj2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshm\\miniconda3\\envs\\AI_Foundation_Proj2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\joshm\\miniconda3\\envs\\AI_Foundation_Proj2\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1126\u001b[0m         hx,\n\u001b[0;32m   1127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1134\u001b[0m     )\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1138\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1146\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Proj2Models import LSTMLanguageModel\n",
    "\n",
    "lstm_model = LSTMLanguageModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pad_token_id=PAD_TOKEN_ID,\n",
    "    top_p=TOP_P,\n",
    "    name=\"LSTM\"\n",
    ").to(device)\n",
    "\n",
    "train_model(lstm_model, device, tokenizer, lstm_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt LSTM (type q to quit): \n",
      "LSTM says: No citizens have suddenly in succession of That his head, the moral emotion?that I love me; no other streets all the mother, through her eye for certain social studies. The dead. Marquis, abruptly, for Ro. Marius, perhaps.\n",
      "Prompt LSTM (type q to quit): \n",
      "LSTM says: strange feasts up in no relief in a day.Ficy. Prraw band; I observe the same classes of your acquaintance, it. I saw a wind which my bosom, certainly indeed, from his pictures among the iron is most\n",
      "Prompt LSTM (type q to quit): \n"
     ]
    }
   ],
   "source": [
    "ask_model(lstm_model, tokenizer, lstm_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mProj2Models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerLanguageModel\n\u001b[0;32m      3\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m TransformerLanguageModel(\n\u001b[0;32m      4\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39mVOCAB_SIZE,\n\u001b[0;32m      5\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39mEMBED_DIM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 15\u001b[0m train_model(transformer_model, device, tokenizer, transformer_model\u001b[38;5;241m.\u001b[39mname)\n",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, device, tokenizer, model_type)\u001b[0m\n\u001b[0;32m     45\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mget_piece_size()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Set up datasets from the given jsonl files for training\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TextDataset(TRAIN_FILE, tokenizer, MAX_TRAIN_SEQ_LEN)\n\u001b[0;32m     49\u001b[0m test_data \u001b[38;5;241m=\u001b[39m TextDataset(TEST_FILE, tokenizer, MAX_TRAIN_SEQ_LEN)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Using pytorch DataLoaders for easy batching, shuffling, etc.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joshm\\OneDrive\\Desktop\\AI Foundations\\Proj2\\Proj2Helper.py:48\u001b[0m, in \u001b[0;36mTextDataset.__init__\u001b[1;34m(self, filepath, tokenizer, max_seq_len)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# With the provided jsonl files from the handout...\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Line by line (with each line being a prompt/completion pair)...\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m     49\u001b[0m         item \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;66;03m# Take the whole line and put it into one string variable\u001b[39;00m\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Proj2Models import TransformerLanguageModel\n",
    "\n",
    "transformer_model = TransformerLanguageModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    pad_token_id=PAD_TOKEN_ID,\n",
    "    top_p=TOP_P,\n",
    "    name=\"Transformer\"\n",
    ").to(device)\n",
    "\n",
    "train_model(transformer_model, device, tokenizer, transformer_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Transformer (type q to quit): \n",
      "LSTM says: It was how they went on the sailors; but never any revs may have once adofor Suply, he took the unfortunate servant, and saw. What? he said, and to the lock my guide us have had merely unusual\n",
      "Prompt Transformer (type q to quit): \n",
      "LSTM says: livid sky. And thy soul will not that could resist. Yes. It made a man whose personal actions so surprised himself a quarter to admit; I know that our return from Daisy. Well? asked Monte Cristo were falling at least to carry to show\n",
      "Prompt Transformer (type q to quit): \n"
     ]
    }
   ],
   "source": [
    "ask_model(transformer_model, tokenizer, transformer_model.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
